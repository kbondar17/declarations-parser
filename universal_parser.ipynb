{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "from typing import Union\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "import typing\n",
    "import io\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "import camelot\n",
    "\n",
    "import pandas as pd\n",
    "%config Completer.use_jedi = False\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm_notebook\n",
    "import logging\n",
    "logging.basicConfig(format=u'%(filename)+13s [ LINE:%(lineno)-4s] %(levelname)-8s %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1209593664.py [ LINE:1   ] WARNING  [2022-03-08 20:18:51,133] ааааа\n"
     ]
    }
   ],
   "source": [
    "logger.warning('ааааа')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_4796/1646197713.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Kirill\\AppData\\Local\\Temp/ipykernel_4796/1646197713.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from declarations-parser.parser\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CorrectHeadersParser:\n",
    "\n",
    "    '''класс для парсинга таблиц, у которых на месте колонки, которые нам нужны'''\n",
    "\n",
    "    def table_splitter(self, table: pd.DataFrame, file_name) -> list[pd.DataFrame]:\n",
    "        '''разделяет таблицы, в которых учреждение указано внутри таблицы'''\n",
    "\n",
    "        def check_if_same(my_array: list) -> bool:\n",
    "            \n",
    "            '''проверяем одинаковые ли колонки'''\n",
    "\n",
    "            if len(set(my_array))>1:\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "            # first = my_array[0]\n",
    "            # for e in my_array[1:]:\n",
    "            #     if e != first:\n",
    "            #         return False\n",
    "            # return True\n",
    "\n",
    "        def get_indexes_to_split(table):\n",
    "            index_to_split = []\n",
    "            for e in range(len(table)):\n",
    "                cols = table.iloc[e,:].values\n",
    "                if check_if_same(cols):\n",
    "                    index_to_split.append(e)\n",
    "            return index_to_split\n",
    "\n",
    "\n",
    "        def split_table(table: pd.DataFrame, index_to_split:Union[int, list[int]], file_name) -> list[pd.DataFrame]:\n",
    "            \"\"\"разделяет таблицу в случае когда название учреждения поместили в середину\n",
    "            \n",
    "                -должность-  -имя-  -зарплата-\n",
    "                        -ГБОУ школа 112-\n",
    "                директор     Ваня    100 руб\n",
    "\n",
    "             \"\"\"\n",
    "            dfs = np.array_split(table, index_to_split)\n",
    "            dfs = [e for e in dfs if len(e) > 0]\n",
    "\n",
    "            result_dfs = []\n",
    "            for df in dfs:\n",
    "                office = df.iloc[0,:][0]\n",
    "                df = df.iloc[1:,:] \n",
    "                df['office'] = office\n",
    "                result_dfs.append(df)\n",
    "            \n",
    "            result_dfs = [e for e in result_dfs if not e.empty]\n",
    "            try:\n",
    "                result_dfs = pd.concat(result_dfs)\n",
    "                return result_dfs\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print('rogue file---', file_name)\n",
    "                \n",
    "        index_to_split = get_indexes_to_split(table)\n",
    "\n",
    "        if not index_to_split:\n",
    "            return table\n",
    "\n",
    "        splitted_dfs = split_table(table, index_to_split, file_name)\n",
    "        return splitted_dfs\n",
    "\n",
    "        \n",
    "    def concat_name(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''соединяем колонки ФИО, если они в разных'''\n",
    "        \n",
    "        if 'name' not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        names_df = df['name']\n",
    "    \n",
    "        if isinstance(names_df, str) or isinstance(names_df, pd.Series):\n",
    "            return df  \n",
    "    \n",
    "        # TODO:\n",
    "        # дропнуть маленькую колонку\n",
    "\n",
    "\n",
    "        names = [' '.join(e) for e in names_df.values]     \n",
    "        \n",
    "        df.drop(columns=['name'], inplace=True)\n",
    "        df['name'] = names\n",
    "        return df\n",
    "\n",
    "\n",
    "    def parse(self, table: pd.DataFrame) -> pd.DataFrame:\n",
    "        table = self.concat_name(table)\n",
    "        table = self.table_splitter(table)\n",
    "        return table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfParser:\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_pdf_to_df(filename) -> list[pd.DataFrame]:\n",
    "        tables = camelot.read_pdf(filename, line_tol=2, joint_tol=10, line_scale=40, copy_text=['v'], pages='1-end') # , flavor='stream' row_tol=10\n",
    "        tables = [e.df for e in tables]\n",
    "        return tables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DocxParser:\n",
    "\n",
    "    def get_docx_tables(self, filename, tab_id=None, **kwargs) -> list[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "            filename:   file name of a Word Document\n",
    "            tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                        When [None] - return a list of DataFrames (parse all tables)\n",
    "        \"\"\"\n",
    "        def read_docx_tab(tab, **kwargs):\n",
    "            vf = io.StringIO()\n",
    "            writer = csv.writer(vf)\n",
    "            for row in tab.rows:\n",
    "                writer.writerow(cell.text for cell in row.cells)\n",
    "            vf.seek(0)\n",
    "            return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "        doc = Document(filename)\n",
    "        if tab_id is None:\n",
    "            return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "        else:\n",
    "            try:\n",
    "                return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "            except IndexError:\n",
    "                print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "                raise\n",
    "            \n",
    "\n",
    "    def convert_docx_to_df(self, filename: str) -> pd.DataFrame:\n",
    "        assert filename.endswith('docx'), 'Формат должен быть .docx!'\n",
    "            \n",
    "        doc = Document(filename)\n",
    "        # TODO: тут взять текст, который потом прикрутить к\n",
    "\n",
    "        doc_tables = self.get_docx_tables(filename) \n",
    "        \n",
    "        return doc_tables\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cols_we_need = ['name','salary', 'position', 'department']\n",
    "        self.all_docs: list[str]\n",
    "\n",
    "        self.docx_parser = DocxParser()\n",
    "        self.pdf_parser = PdfParser()\n",
    "\n",
    "        self.parse_correct_headers = 'CorrectHeadersParser()'     \n",
    "        self.parse_incorrect_headers = ''\n",
    "\n",
    "        self.data_cleaner = 'DataCleaner()'\n",
    "\n",
    "    @staticmethod\n",
    "    def rename_col(col: str) -> str:\n",
    "\n",
    "        print('col before rename cols --', col)\n",
    "        col = col.lower()\n",
    "        if re.search(pattern='(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество)', string=col):\n",
    "            return \"name\"\n",
    "\n",
    "        elif re.search(pattern='(cреднемесячная|зарпл.|плат[ы, а]|заработн[ой, ая] плат[а, ы]|cреднемесячн[ая, ой]|зарплат[а, ной, ы])', string=col):\n",
    "            return \"salary\"\n",
    "\n",
    "        elif re.search(pattern='(должност[ь, и, ей])', string=col): \n",
    "\n",
    "            return 'position'\n",
    "\n",
    "        elif re.search(pattern='(предприяти[е,я]|учреждени[е,я]|юридическое лицо)', string=col):\n",
    "            return 'department'\n",
    "\n",
    "        return col\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def check_if_columns_ok(cols: tuple) -> bool:\n",
    "        '''проверяем, есть ли в заголовках таблицы название предприятия и другая инфа'''\n",
    "        \n",
    "        cols = list(map(str, cols))\n",
    "        cols = list(map(str.lower, cols))\n",
    "        print('зашли в проверку колонок ---', cols)\n",
    "        ok_cols = 0\n",
    "        company_found = False\n",
    "        for col in cols:\n",
    "            company_pattern = '(предприяти[е,я]|учреждени[е,я]|юридическ[ое,ие])'\n",
    "            res = re.search(pattern=company_pattern, string=col)\n",
    "            if res:\n",
    "                company_found = True\n",
    "                continue\n",
    "            \n",
    "            name_salary_position_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|плат[ы, а]|заработная|плата|cреднемесячн[ая, ой]|зарплат[а, ной, ы]|должность|)'\n",
    "            \n",
    "            res = re.search(pattern=name_salary_position_pattern, string=col)\n",
    "            if res:\n",
    "                ok_cols+=1\n",
    "\n",
    "        if company_found and ok_cols > 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def parse_folder(self, file_path, destination_path):\n",
    "        for file in os.listdir(file_path):\n",
    "            try:\n",
    "                df = self.parse_file(file_path)\n",
    "                df.to_excel(destination_path + file_path)\n",
    "            except Exception as ex:\n",
    "                print(file_path)\n",
    "                print(ex)\n",
    "                print('===')\n",
    "\n",
    "\n",
    "    def parse_file(self, file: str):\n",
    "        if file.endswith('.pdf'):\n",
    "            tables = self.pdf_parser.convert_pdf_to_df(file)\n",
    "        \n",
    "        elif file.endswith('docx'):\n",
    "            tables = self.docx_parser.convert_docx_to_df(file)\n",
    "\n",
    "        else:\n",
    "            logger.error('Допустимы расширения: pdf, docx')\n",
    "\n",
    "        parsed_tables = []\n",
    "        for table in tables:\n",
    "            \n",
    "            columns_ok = self.check_if_columns_ok(table)\n",
    "            if not columns_ok:\n",
    "            # пометить?\n",
    "            # если учреждения нет - смотрим параграфы. \n",
    "            # пытаемся найти заголовки, если находим - идем дальше, если нет - дропаем и метим как непаршеный\n",
    "\n",
    "                pass\n",
    "\n",
    "            else:                \n",
    "                # если заголовки ок, оставляем только нужные\n",
    "\n",
    "                table.columns = [self.rename_col(col) for col in table.columns]\n",
    "\n",
    "                \n",
    "                cols_to_leave = [col for col in table.columns if col in self.cols_we_need]\n",
    "                cols_to_leave = set(cols_to_leave)\n",
    "                table = table[cols_to_leave]\n",
    "                \n",
    "                # проверяем на наличие вложенных таблиц и фио, разнесенных на несколько стаоблцов\n",
    "                table = self.parse_correct_headers.parse(table)\n",
    "                # убираем лишние ячейки и символы\n",
    "                table = self.data_cleaner.clean_df(table)\n",
    "                parsed_tables.append(table)\n",
    "                        \n",
    "        if isinstance(parsed_tables, list):\n",
    "            if parsed_tables:\n",
    "                concat_tables = pd.concat(parsed_tables)\n",
    "                return concat_tables\n",
    "    \n",
    "        elif isinstance(parsed_tables, pd.DataFrame):\n",
    "            if not parsed_tables.empty:\n",
    "                return concat_tables\n",
    "        \n",
    "\n",
    "\n",
    "base = 'data_ids/pdf/converted/'\n",
    "file = '189273_2020_Rektor,_prorektory,_glavnyi_bukhgalter.pdf'\n",
    "def convert_pdf_to_df(filename) -> list[pd.DataFrame]:\n",
    "    tables = camelot.read_pdf(file, line_tol=2, joint_tol=10, line_scale=40, copy_text=['v'], pages='1-end') # , flavor='stream' row_tol=10\n",
    "    tables = [e.df for e in tables]\n",
    "    return tables\n",
    "\n",
    "file = 'data_ids/pdf/converted/189273_2020_Rektor,_prorektory,_glavnyi_bukhgalter.pdf'\n",
    "\n",
    "# convert_pdf_to_df(file)\n",
    "#parser = Parser()\n",
    "# res = parser.parse_file(base + file)\n",
    "# res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_ids/pdf/converted/189273_2020_Rektor,_prorektory,_glavnyi_bukhgalter.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = PdfParser()\n",
    "pdf.convert_pdf_to_df(base + file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137dc9a7529e050f0d3404627e217fd4120b6229f927507e6c7e6283ad4b3698"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
