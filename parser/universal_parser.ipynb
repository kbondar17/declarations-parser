{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "from typing import Union\n",
    "import csv\n",
    "import statistics\n",
    "import pdf2docx\n",
    "\n",
    "import pickle\n",
    "\n",
    "import camelot\n",
    "import typing\n",
    "import io\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "%config Completer.use_jedi = False\n",
    "from pathlib import Path\n",
    "# import tqdm.notebook.tqdm as tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.basicConfig(format=u'%(filename)+13s [ LINE:%(lineno)-4s] %(levelname)-8s %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from docx2python import docx2python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PdfParser:\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_pdf_to_df(filename) -> list[pd.DataFrame]:\n",
    "        tables = camelot.read_pdf(str(filename), line_tol=2, joint_tol=10, line_scale=40, copy_text=['v'], pages='1-end') # , flavor='stream' row_tol=10\n",
    "        tables = [e.df for e in tables]\n",
    "        return tables\n",
    "\n",
    "\n",
    "\n",
    "# base = 'data_idus/pdf/converted/'\n",
    "# file = '189273_2020_Rektor,_prorektory,_glavnyi_bukhgalter.pdf'\n",
    "file = \"D:/PROGR/LEARN_PYTHON/Declarator/declarations-parser/data_ids/pdf/converted/90569_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\"\n",
    "# par = PdfParser()\n",
    "# res = par.convert_pdf_to_df(file)\n",
    "# res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100206_2019',\n",
       " '101232_2018',\n",
       " '102031_2019',\n",
       " '102421_2019',\n",
       " '102541_2019',\n",
       " '102585_2019',\n",
       " '102586_2019',\n",
       " '102907_2019',\n",
       " '103026_2019',\n",
       " '104576_2019',\n",
       " '104619_2019',\n",
       " '176299_2020',\n",
       " '177336_2020',\n",
       " '177672_2020',\n",
       " '178290_2020',\n",
       " '178303_2020',\n",
       " '178403_2020',\n",
       " '178414_2020',\n",
       " '178423_2020',\n",
       " '179161_2020',\n",
       " '179252_2020',\n",
       " '179394_2020',\n",
       " '179467_2020',\n",
       " '179512_2020',\n",
       " '179590_2020',\n",
       " '179663_2020',\n",
       " '179911_2020',\n",
       " '180112_2020',\n",
       " '180258_2020',\n",
       " '180263_2020',\n",
       " '180371_2020',\n",
       " '180385_2020',\n",
       " '182639_2020',\n",
       " '183392_2020',\n",
       " '183413_2020',\n",
       " '184287_2018',\n",
       " '184503_2020',\n",
       " '184919_2020',\n",
       " '186491_2020',\n",
       " '186613_2020',\n",
       " '187331_2020',\n",
       " '187741_2020',\n",
       " '187742_2020',\n",
       " '188290_2020',\n",
       " '189123_2020',\n",
       " '189320_2020',\n",
       " '189322_2020',\n",
       " '189496_2020',\n",
       " '189701_2020',\n",
       " '189856_2020',\n",
       " '83292_2016',\n",
       " '83310_2016',\n",
       " '83311_2017',\n",
       " '83312_2018',\n",
       " '83316_2018',\n",
       " '83318_2017',\n",
       " '83321_2018',\n",
       " '83335_2018',\n",
       " '83336_2017',\n",
       " '83338_2018',\n",
       " '83339_2017',\n",
       " '83340_2018',\n",
       " '83341_2017',\n",
       " '83342_2018',\n",
       " '83343_2017',\n",
       " '83344_2016',\n",
       " '83349_2018',\n",
       " '83350_2017',\n",
       " '83360_2018',\n",
       " '83364_2018',\n",
       " '83365_2018',\n",
       " '83376_2018',\n",
       " '83378_2018',\n",
       " '83381_2019',\n",
       " '83382_2018',\n",
       " '83383_2017',\n",
       " '83384_2017',\n",
       " '83735_2018',\n",
       " '83736_2017',\n",
       " '84462_2018',\n",
       " '84463_2017',\n",
       " '84524_2019',\n",
       " '84547_2019',\n",
       " '84548_2018',\n",
       " '84562_2019',\n",
       " '84563_2018',\n",
       " '84753_2019',\n",
       " '84754_2018',\n",
       " '84755_2017',\n",
       " '84860_2018',\n",
       " '84903_2017',\n",
       " '84904_2018',\n",
       " '84925_2019',\n",
       " '85029_2018',\n",
       " '85082_2018',\n",
       " '85083_2017',\n",
       " '85273_2019',\n",
       " '85511_2019',\n",
       " '85512_2018',\n",
       " '85861_2019',\n",
       " '86671_2019',\n",
       " '86741_2019',\n",
       " '86949_2019',\n",
       " '87364_2018',\n",
       " '88260_2018',\n",
       " '88669_2018',\n",
       " '88670_2017',\n",
       " '88775_2018',\n",
       " '88776_2017',\n",
       " '88942_2019',\n",
       " '88943_2018',\n",
       " '88944_2017',\n",
       " '90303_2018',\n",
       " '90629_2017',\n",
       " '90665_2019',\n",
       " '90666_2018',\n",
       " '90871_2018',\n",
       " '92762_2019',\n",
       " '92796_2019',\n",
       " '95518_2019',\n",
       " '95807_2019',\n",
       " '95822_2019',\n",
       " '96034_2019',\n",
       " '96354_2019',\n",
       " '96410_2019',\n",
       " '96461_2019',\n",
       " '96657_2019',\n",
       " '96866_2019',\n",
       " '97332_2019',\n",
       " '97367_2019',\n",
       " '98238_2019',\n",
       " '99715_2019',\n",
       " 'test_rogue.docx'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = r'D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\docx'\n",
    "folder_with_ok = r'D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\docx\\cool\\ok2'\n",
    "\n",
    "ne_ok_ids = []\n",
    "ok_ids = []\n",
    "all_ids = []\n",
    "\n",
    "for e in os.listdir(folder):\n",
    "    if e.endswith('docx'):\n",
    "        all_ids.append('_'.join(e.split('_')[:2]))\n",
    "\n",
    "for e in os.listdir(folder_with_ok):\n",
    "    if e.endswith('xlsx'):\n",
    "        ok_ids.append('_'.join(e.split('_')[:2]))\n",
    "\n",
    "# print(len(all_ids))\n",
    "# print(len(ok_ids))\n",
    "\n",
    "\n",
    "\n",
    "all_ids = set(all_ids)\n",
    "ok_ids = set(ok_ids)\n",
    "\n",
    "bad_ids = all_ids - ok_ids\n",
    "bad_ids\n",
    "\n",
    "#for e in os.listdir(folder_with_ok):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CorrectHeadersParser:\n",
    "\n",
    "    '''класс для парсинга таблиц, у которых на месте колонки, которые нам нужны'''\n",
    "\n",
    "    def table_splitter(self, table: pd.DataFrame) -> list[pd.DataFrame]:\n",
    "        '''разделяет таблицы, в которых учреждение указано внутри таблицы'''\n",
    "\n",
    "        def check_if_same(my_array: list) -> bool:\n",
    "            \n",
    "            '''проверяем одинаковые ли колонки'''\n",
    "\n",
    "            if len(set(my_array))>1:\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "            # first = my_array[0]\n",
    "            # for e in my_array[1:]:\n",
    "            #     if e != first:\n",
    "            #         return False\n",
    "            # return True\n",
    "\n",
    "        def get_indexes_to_split(table):\n",
    "            index_to_split = []\n",
    "            for e in range(len(table)):\n",
    "                cols = table.iloc[e,:].values\n",
    "                if check_if_same(cols):\n",
    "                    index_to_split.append(e)\n",
    "            return index_to_split\n",
    "\n",
    "\n",
    "        def split_table(table: pd.DataFrame, index_to_split:Union[int, list[int]]) -> list[pd.DataFrame]:\n",
    "            \"\"\"разделяет таблицу в случае когда название учреждения поместили в середину вот так:\n",
    "\n",
    "                -должность-  -имя-  -зарплата-\n",
    "                        -ГБОУ школа 112-\n",
    "                 директор     Ваня    100 руб\n",
    "\n",
    "             \"\"\"\n",
    "            dfs = np.array_split(table, index_to_split)\n",
    "            dfs = [e for e in dfs if len(e) > 0]\n",
    "\n",
    "            result_dfs = []\n",
    "            for df in dfs:\n",
    "                office = df.iloc[0,:][0]\n",
    "                df = df.iloc[1:,:] \n",
    "                df['office'] = office\n",
    "                result_dfs.append(df)\n",
    "            \n",
    "            result_dfs = [e for e in result_dfs if not e.empty]\n",
    "            try:\n",
    "                result_dfs = pd.concat(result_dfs)\n",
    "                return result_dfs\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print('rogue file---', table)\n",
    "                \n",
    "        index_to_split = get_indexes_to_split(table)\n",
    "\n",
    "        if not index_to_split:\n",
    "            return table\n",
    "\n",
    "        splitted_dfs = split_table(table, index_to_split)\n",
    "        return splitted_dfs\n",
    "\n",
    "        \n",
    "    def concat_name(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''соединяем колонки ФИО, если они в разных'''\n",
    "        \n",
    "        if 'name' not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        names_df = df['name']\n",
    "    \n",
    "        if isinstance(names_df, str) or isinstance(names_df, pd.Series):\n",
    "            return df  \n",
    "    \n",
    "        # TODO:\n",
    "        # дропнуть маленькую колонку\n",
    "\n",
    "\n",
    "        names = [' '.join(e) for e in names_df.values]     \n",
    "        \n",
    "        df.drop(columns=['name'], inplace=True)\n",
    "        df['name'] = names\n",
    "        return df\n",
    "\n",
    "\n",
    "    def parse(self, table: pd.DataFrame) -> pd.DataFrame:\n",
    "        # table = self.concat_name(table)\n",
    "        table = self.table_splitter(table)\n",
    "        return table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\"убирает лишние данные\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_unwanted_symbols(df):        \n",
    "        # TODO: чистка всех колонок\n",
    "        df = df.applymap(lambda x: str(x).replace('\\n', ' '))\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_unwanted_cells(df):\n",
    "        # убирает ячейки с нумерацией\n",
    "        # print('--- DataCleaner.remove_unwanted_cells ---', df.columns)\n",
    "        #TODO: почему тут только должность?\n",
    "        df = df[~df['position'].astype(str).str.isdigit()]\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_short_rows(df):\n",
    "        # удаляет ряды с недостаточными данными\n",
    "        # ! должно применяться после выбора норм колонок\n",
    "        to_remove = []\n",
    "        for tup in df.itertuples():\n",
    "            res = [len(str(e)) for e in tup]\n",
    "            if statistics.mean(res) < 5:\n",
    "                to_remove.append(tup.Index)\n",
    "        \n",
    "\n",
    "        df.drop(to_remove, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def merge_if_three_names(df:pd.DataFrame):\n",
    "        # TODO: !!!!\n",
    "        pass             \n",
    "\n",
    "    def clean_df(self, df):\n",
    "        df = self.remove_unwanted_symbols(df)\n",
    "        df = self.remove_unwanted_cells(df)\n",
    "\n",
    "        df = self.remove_short_rows(df)\n",
    "        # print('!!!',df)\n",
    "\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DocxParser:\n",
    "\n",
    "    def get_docx_tables(self, filename, tab_id=None, **kwargs) -> list[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "            filename:   file name of a Word Document\n",
    "            tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                        When [None] - return a list of DataFrames (parse all tables)\n",
    "        \"\"\"\n",
    "        def read_docx_tab(tab, **kwargs):\n",
    "            vf = io.StringIO()\n",
    "            writer = csv.writer(vf)\n",
    "            for row in tab.rows:\n",
    "                writer.writerow(cell.text for cell in row.cells)\n",
    "            vf.seek(0)\n",
    "            return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "        doc = Document(filename)\n",
    "        if tab_id is None:\n",
    "            return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "        else:\n",
    "            try:\n",
    "                return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "            except IndexError:\n",
    "                print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "                raise\n",
    "            \n",
    "\n",
    "    def convert_docx_to_df(self, filename: str) -> pd.DataFrame:\n",
    "        assert filename.endswith('docx'), 'Формат должен быть .docx!'\n",
    "            \n",
    "        doc = Document(filename)\n",
    "        # TODO: тут взять текст, который потом прикрутить к\n",
    "\n",
    "        doc_tables = self.get_docx_tables(filename) \n",
    "        \n",
    "        return doc_tables\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IncorrectHeaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5512/1668124363.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\для_которых_нужен_перевод_в_ворд'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5512/1668124363.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf_parser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPdfParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_correct_headers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCorrectHeadersParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mincorrect_headers_parser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIncorrectHeaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_cleaner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataCleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IncorrectHeaders' is not defined"
     ]
    }
   ],
   "source": [
    "class Parser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cols_we_need = ['name','salary', 'position', 'department']\n",
    "        self.all_docs: list[str]\n",
    "        self.docx_parser = DocxParser()\n",
    "        self.pdf_parser = PdfParser()\n",
    "        self.parse_correct_headers = CorrectHeadersParser()\n",
    "        self.incorrect_headers_parser = IncorrectHeaders()\n",
    "        self.data_cleaner = DataCleaner()\n",
    "\n",
    "    @staticmethod\n",
    "    def rename_col(col: str) -> str:\n",
    "\n",
    "        print('col before rename cols --', col)\n",
    "        col = str(col).lower()\n",
    "        if re.search(pattern='(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество)', string=col):\n",
    "            return \"name\"\n",
    "\n",
    "        elif re.search(pattern='(рублей|руб|cреднемесячная|зарпл.|плат[ы, а]|заработн[ой, ая] плат[а, ы]|cреднемесячн[ая, ой]|зарплат[а, ной, ы])', string=col):\n",
    "            return \"salary\"\n",
    "\n",
    "        elif re.search(pattern='(должност[ь, и, ей])', string=col): \n",
    "\n",
    "            return 'position'\n",
    "\n",
    "        elif re.search(pattern='(предприяти[е,я]|учреждени[е,я]|юридическое лицо)', string=col):\n",
    "            return 'department'\n",
    "\n",
    "        return col\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def check_if_columns_ok(cols: tuple) -> bool:\n",
    "        '''проверяем, есть ли в заголовках таблицы название предприятия и другая инфа'''\n",
    "        \n",
    "        cols = list(map(str, cols))\n",
    "        cols = list(map(str.lower, cols))\n",
    "        ok_cols = 0\n",
    "        company_found = False\n",
    "        for col in cols:\n",
    "            company_pattern = '(предприяти[е,я]|учреждени[е,я]|юридическ[ое,ие])'\n",
    "            res = re.search(pattern=company_pattern, string=col)            \n",
    "            if res:\n",
    "                company_found = True\n",
    "                continue\n",
    "                      \n",
    "            name_salary_position_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|плат[ы, а]|заработная|плата|cреднемесячн[ая, ой]|зарплат[а, ной, ы]|должность)'\n",
    "            res = re.search(pattern=name_salary_position_pattern, string=col)\n",
    "            if res:\n",
    "                ok_cols+=1\n",
    "\n",
    "        if company_found and ok_cols > 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def parse_folder(self, file_path, destination_path):\n",
    "        for file in os.listdir(file_path):\n",
    "            try:\n",
    "                df = self.parse_file(file_path)\n",
    "                df.to_excel(destination_path + file_path)\n",
    "            except Exception as ex:\n",
    "                print(file_path)\n",
    "                print(ex)\n",
    "                print('===')\n",
    "\n",
    "\n",
    "    def parse_file(self, file: str):\n",
    "        \n",
    "        if str(file).endswith('.pdf'):\n",
    "            tables = self.pdf_parser.convert_pdf_to_df(file)\n",
    "        \n",
    "        elif file.endswith('docx'):\n",
    "            tables = self.docx_parser.convert_docx_to_df(file)\n",
    "\n",
    "        else:\n",
    "            logger.error('Допустимы расширения: pdf, docx')\n",
    "\n",
    "        parsed_tables = []\n",
    "\n",
    "        for table in tables:\n",
    "            # удалить кал из маленьких ячеек?\n",
    "                         \n",
    "            columns_ok = self.check_if_columns_ok(table)\n",
    "\n",
    "            if not columns_ok:\n",
    "                # колонки непправильные. идем пытаться найти нормальные. для этого мы весь файл передаем в Incorrect и скипаем цикл \n",
    "                \n",
    "                parsing_ok, tables = self.incorrect_headers_parser.parse(Path(file))\n",
    "                \n",
    "                if parsing_ok:\n",
    "                    for table in tables:\n",
    "                        # оставляем нужные колонки\n",
    "                        table.columns = [self.rename_col(col) for col in table.columns]\n",
    "                        cols_to_leave = [col for col in table.columns if col in self.cols_we_need]\n",
    "                        cols_to_leave = set(cols_to_leave)\n",
    "                        table = table[cols_to_leave]\n",
    "                        # проверяем на наличие вложенных таблиц и фио, разнесенных на несколько стаоблцов\n",
    "                        table = self.parse_correct_headers.parse(table)\n",
    "                        # убираем лишние ячейки и символы\n",
    "                        table = self.data_cleaner.clean_df(table)\n",
    "                        parsed_tables.append(table)\n",
    "                    break\n",
    "\n",
    "                else:                    \n",
    "                    # TODO: сохранить файл в папку нераспаршенных \n",
    "                    logger.warning('Не удалось распарсить ----', file)\n",
    "\n",
    "            elif columns_ok:                \n",
    "                # если заголовки ок \n",
    "                # оставляем только нужные колонки \n",
    "                pass                \n",
    "                table.columns = [self.rename_col(col) for col in table.columns]\n",
    "                cols_to_leave = [col for col in table.columns if col in self.cols_we_need]\n",
    "                cols_to_leave = set(cols_to_leave)\n",
    "                table = table[cols_to_leave]\n",
    "                # проверяем на наличие вложенных таблиц и фио, разнесенных на несколько стаоблцов\n",
    "                table = self.parse_correct_headers.parse(table)\n",
    "                # убираем лишние ячейки и символы\n",
    "                table = self.data_cleaner.clean_df(table)\n",
    "                parsed_tables.append(table)\n",
    "\n",
    "\n",
    "        if isinstance(parsed_tables, list):\n",
    "            if parsed_tables:\n",
    "                concat_tables = pd.concat(parsed_tables)\n",
    "                return concat_tables\n",
    "    \n",
    "        elif isinstance(parsed_tables, pd.DataFrame):\n",
    "            if not parsed_tables.empty:\n",
    "                return concat_tables\n",
    "        \n",
    "\n",
    "\n",
    "base = 'data_ids/pdf/converted/'\n",
    "file = '189273_2020_Rektor,_prorektory,_glavnyi_bukhgalter.pdf'\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\100185_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(sport).pdf\"\n",
    "\n",
    "parser = Parser()\n",
    "folder = Path(r'D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\для_которых_нужен_перевод_в_ворд')\n",
    "\n",
    "\n",
    "\n",
    "# for e in os.listdir(folder):\n",
    "#     if e.endswith('.pdf'):\n",
    "#         res = parser.parse_file(folder / e)\n",
    "#         with open(e+'.pkl','wb') as f:\n",
    "#             pickle.dump(res, f)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88766_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "88767_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "88768_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "89001_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "89058_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "89060_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "89060_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "89062_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "89303_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii_(2017-2019_gody).pdf\n",
      "89868_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "89869_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "90569_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "90628_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "90981_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "95804_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "95917_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\n",
      "ne_ok\n",
      "ok\n",
      "temp.txt\n",
      "temp_to_delete_88766_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_88767_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_88768_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_89058_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_89060_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_89062_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_89303_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii_(2017-2019_gody).docx\n",
      "temp_to_delete_89868_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_89869_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_90569_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_90628_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_90981_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_95804_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n",
      "temp_to_delete_95917_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file = r'88767_2018_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf'\n",
    "file = r'D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\parser\\88766_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pkl'\n",
    "\n",
    "# with open('test.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    loaded_df = pickle.load(f)\n",
    "\n",
    "# loaded_df\n",
    "for e in os.listdir(folder):\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start to convert D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\104563_2019_Rektor,_prorektory,_glavnyi_bukhgalter.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/1) Page 1\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[ERROR] [WinError 32] Процесс не может получить доступ к файлу, так как этот файл занят другим процессом: 'D:\\\\PROGR\\\\LEARN_PYTHON\\\\Declarator\\\\declarations-parser\\\\data_ids\\\\pdf\\\\converted\\\\temp_to_delete_104563_2019_Rektor,_prorektory,_glavnyi_bukhgalter.docx'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/PROGR/LEARN_PYTHON/Declarator/declarations-parser/data_ids/pdf/converted/temp_to_delete_104563_2019_Rektor,_prorektory,_glavnyi_bukhgalter.docx')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " \n",
    "# extract docx content\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\docx\\102585_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(kul'tura).docx\"\n",
    "# file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\docx\\101232_2018_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(obrazovanie).docx\"\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\docx\\184287_2018_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(obrazovanie).docx\"\n",
    "# file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\docx\\102585_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(kul'tura).docx\"\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\docx\\179512_2020_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class IncorrectHeaders:\n",
    "    \"\"\"класс для таблиц с неопределенными заголовками.\n",
    "        1. Пытаемся найти название учреждений в объединенных ячейках.\n",
    "        2. Если не получается, для учреждения берем текст, предшествующий таблице. \n",
    "    \"\"\"\n",
    "\n",
    "    # если прошелся по таблице и нашел вложения внутри - пусть это будет офис.\n",
    "    # если не нашел - берем название офиса из абзацев вокруг таблиц (если их число плюс минус совпадает)\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        # TODO: добавить обработку чисто docx \n",
    "\n",
    "        # self.docx_parser = DocxParser()\n",
    "        # self.pdf_parser = PdfParser()\n",
    "\n",
    "    def drop_col_with_N(df:pd.DataFrame):\n",
    "        expr = '(№|п/п)'\n",
    "        for c in df.columns:\n",
    "            if re.search(expr, c):\n",
    "                df.drop(columns=c, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def drop_short_cols(df: pd.DataFrame):\n",
    "        len_df = df.applymap(len)\n",
    "        for c in df.columns:\n",
    "            if len_df[c].mean() < 4:\n",
    "                df.drop(columns=c, inplace=True)\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def table_splitter(self, table: pd.DataFrame) -> tuple[bool, list[pd.DataFrame]]:\n",
    "        '''разделяет таблицы, в которых учреждение указано внутри таблицы'''\n",
    "\n",
    "        def check_if_same(my_array: list) -> bool:\n",
    "            '''проверяем одинаковые ли колонки'''\n",
    "\n",
    "            if len(set(my_array))>1:\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "\n",
    "        def get_indexes_to_split(table):\n",
    "            '''определяем индекс строки таблицы, по которому надо разделить'''\n",
    "\n",
    "            index_to_split = []\n",
    "            for e in range(len(table)):\n",
    "                cols = table.iloc[e,:].values\n",
    "                if check_if_same(cols):\n",
    "                    index_to_split.append(e)\n",
    "            return index_to_split\n",
    "\n",
    "                                                                                                #если разделили и нашли офис - True \n",
    "        def split_table(table: pd.DataFrame, index_to_split:Union[int, list[int]]) -> tuple[bool, list[pd.DataFrame]]:\n",
    "            \"\"\"разделяет таблицу в случае когда название учреждения поместили в середину вот так:\n",
    "                -должность-  -имя-  -зарплата-\n",
    "                        -ГБОУ школа 112-\n",
    "                 директор     Ваня    100 руб\n",
    "\n",
    "             \"\"\"\n",
    "            dfs = np.array_split(table, index_to_split)\n",
    "            dfs = [e for e in dfs if len(e) > 0]\n",
    "\n",
    "            result_dfs = []\n",
    "            for df in dfs:\n",
    "                office = df.iloc[0,:][0]\n",
    "                df = df.iloc[1:,:] \n",
    "                df['office'] = office\n",
    "                result_dfs.append(df)\n",
    "            \n",
    "            result_dfs = [e for e in result_dfs if not e.empty]\n",
    "            try:\n",
    "                result_dfs = pd.concat(result_dfs)\n",
    "                return result_dfs\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                # print('rogue file---', table)\n",
    "                \n",
    "        index_to_split = get_indexes_to_split(table)\n",
    "\n",
    "        if not index_to_split:\n",
    "            return False, table\n",
    "\n",
    "        splitted_dfs = split_table(table, index_to_split)\n",
    "        return True, splitted_dfs\n",
    "\n",
    "#        бесконечно распознается, не доходит до создания дока! \n",
    "\n",
    "    def convert_pdf_to_docx_to_find_info(self, filename: Path) -> Path:\n",
    "        # переводим пфд в ворд\n",
    "        assert str(filename).endswith('.pdf'), 'Файл должен быть в PDF !'\n",
    "        folder = filename.parents[0]\n",
    "\n",
    "        orig_file_name = filename.name.strip('.pdf')                 \n",
    "        new_name = 'temp_to_delete_' + orig_file_name + '.docx'\n",
    "\n",
    "        pdf2docx.parse(str(filename), str(folder / new_name))\n",
    "        return folder / new_name\n",
    "\n",
    "    @staticmethod\n",
    "    def check_if_columns_ok(cols: tuple) -> bool:\n",
    "        '''проверяем, есть ли в заголовках таблицы название предприятия и другая инфа'''\n",
    "        \n",
    "        cols = list(map(str, cols))\n",
    "        cols = list(map(str.lower, cols))\n",
    "\n",
    "        ok_cols = 0\n",
    "        for col in cols:\n",
    "            name_salary_position_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|плат[ы, а]|заработная|плата|cреднемесячн[ая, ой]|зарплат[а, ной, ы]|должность)'\n",
    "            \n",
    "            res = re.search(pattern=name_salary_position_pattern, string=col)\n",
    "            if res:\n",
    "                ok_cols+=1\n",
    "\n",
    "        if ok_cols > 1:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    def find_ok_cols(self, df:pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        cols = df.columns\n",
    "      \n",
    "       # если колонки норм, отдаем df\n",
    "        if self.check_if_columns_ok(cols):\n",
    "            return df\n",
    "\n",
    "        i = -1\n",
    "        for _, row in df.iterrows():\n",
    "            i+=1\n",
    "            found_cols =  self.check_if_columns_ok(list(row))   \n",
    "            if found_cols:\n",
    "\n",
    "                df.columns = df.iloc[i,:]\n",
    "                return df.iloc[i+1:,:]\n",
    "            if i > 5:\n",
    "                break\n",
    "        \n",
    "        # если колонки не ок -\n",
    "\n",
    "        print('-'*10)\n",
    "        print('не найдены нормальные колонки')\n",
    "        print(df.head(3))\n",
    "        print('-'*10)\n",
    "\n",
    "\n",
    "#        raise ValueError('Incorrect Headers find_ok_cols --- в df не найдены нормальные колонки')\n",
    "\n",
    "\n",
    "    \n",
    "    def convert_pdf_to_dfs(self, filename: str) -> list[pd.DataFrame]:\n",
    "#        print('filename in convert_pdf_to_df -----',filename)\n",
    "        try:\n",
    "            tables = camelot.read_pdf(str(filename), line_tol=2, joint_tol=10, line_scale=40, copy_text=[\n",
    "                                    'v'], pages='1-end')  # , flavor='stream' row_tol=10\n",
    "            tables = [e.df for e in tables]\n",
    "            return tables\n",
    "\n",
    "        except Exception as ex:\n",
    "            logger.error('file --- %s', filename)\n",
    "            logger.error('Exception --- %s', ex)\n",
    "\n",
    "\n",
    "    def detect_headers_in_raw_doc(self, filename) -> list[pd.DataFrame]:\n",
    "        \n",
    "        def get_headers(filename: str) -> list[str]: #filename:docx\n",
    "\n",
    "            doc = docx2python(filename)\n",
    "\n",
    "            table_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|должность)'\n",
    "\n",
    "            offices = []\n",
    "            gathering_office_info = ''\n",
    "\n",
    "            for paragraph in doc.body_runs: #параграфы в виде вложенных листов\n",
    "\n",
    "                paragraph = sum(sum(paragraph, []), [])\n",
    "                paragraph_text = ''\n",
    "                for e in paragraph:\n",
    "                    try:\n",
    "                        paragraph_text += ' ' + e[0] + ' '\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                \n",
    "                paragraph_text = paragraph_text.lower()\n",
    "                its_table = re.findall(pattern=table_pattern, string=paragraph_text)\n",
    "                \n",
    "                if not its_table:\n",
    "                    gathering_office_info+=paragraph_text\n",
    "                \n",
    "                elif its_table:\n",
    "                    offices.append(gathering_office_info)\n",
    "                    gathering_office_info=''\n",
    "\n",
    "            return [e for e in offices if e]\n",
    "\n",
    "        def compile_office_info_and_df(filename, departments: list) -> list[pd.DataFrame]:\n",
    "            # все правильно. логика такая, что камелотом лучше парсить!\n",
    "            # а док только для загов таблиц\n",
    "\n",
    "            tables = self.convert_pdf_to_df_and_find_tables(filename)\n",
    "\n",
    "            ok_dfs = []\n",
    "\n",
    "            print('Количество заголовков --- ', len(departments))\n",
    "            print('Количество таблиц --- ', len(tables))\n",
    "            \n",
    "            if len(departments) - len(tables) == 1:\n",
    "                departments.pop()\n",
    "\n",
    "\n",
    "            if len(departments) == len(tables):\n",
    "                for table, dep in zip(tables, departments):\n",
    "                    table['Учреждение'] = dep\n",
    "                    table['Учреждение'][0] = 'Учреждение'\n",
    " \n",
    "                    ok_dfs.append(table)\n",
    "          \n",
    "                return ok_dfs\n",
    "            \n",
    "            raise ValueError('Разное число таблиц и учреждений')\n",
    "        \n",
    "        temp_docfile = self.convert_pdf_to_docx_to_find_info(filename) # получили path временного docx файла\n",
    "        departments = get_headers(temp_docfile)\n",
    "        dfs = compile_office_info_and_df(filename, departments)\n",
    "        return dfs\n",
    "\n",
    "\n",
    "    def parse(self, filename: Path) -> tuple[bool, pd.DataFrame]:\n",
    "        # пытаемся найти учреждения в теле таблиц\n",
    "\n",
    "        #TODO: добавить проверку doc или pdf\n",
    "\n",
    "        # должны быть просто таблицы\n",
    "        # и вся обработка должна быть тут, по этапам. иначе макароны\n",
    "        tables = self.convert_pdf_to_df_and_find_tables(filename)\n",
    "        # дропаем маленькие колонки\n",
    "        tables = [self.drop_col_with_N(e) for e in tables]\n",
    "        tables = [self.drop_short_cols(e) for e in tables]\n",
    "        tables = [self.find_ok_cols(e) for e in tables]\n",
    "        \n",
    "\n",
    "        # tables = [e for e in tables if type(e) == pd.DataFrame]\n",
    "        \n",
    "\n",
    "\n",
    "        # tables_with_ok_headers = []\n",
    "        # if not tables:\n",
    "        #     return False, []\n",
    "        \n",
    "        # for table in tables:\n",
    "        #     res, df = self.table_splitter(table)\n",
    "        #     if res:\n",
    "        #         tables_with_ok_headers.append(df)\n",
    "\n",
    "        #     if not res:\n",
    "        #         del tables\n",
    "        #         # идем парсить весь док, чтобы достать учреждения из текста перед таблицей\n",
    "        #         dfs = self.detect_headers_in_raw_doc(filename)\n",
    "        #         for df in dfs:\n",
    "        #             tables_with_ok_headers.append(df)\n",
    "        #         break\n",
    "        \n",
    "\n",
    "        \n",
    "        #TODO: переделать удаление временного дока\n",
    "\n",
    "        return bool(tables_with_ok_headers), tables_with_ok_headers        \n",
    "        \n",
    "\n",
    "       # 'temp_to_delete_D:\\\\PROGR\\\\LEARN_PYTHON\\\\Declarator\\\\declarations-parser\\\\data_ids\\\\pdf\\\\converted\\\\для которых нужен перевод в ворд\\\\88766_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\для_которых_нужен_перевод_в_ворд\\89001_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\"\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\100185_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(sport).pdf\"\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\104563_2019_Rektor,_prorektory,_glavnyi_bukhgalter.pdf\"\n",
    "\n",
    "incor_parser = IncorrectHeaders()\n",
    "\n",
    "temp_file = incor_parser.convert_pdf_to_docx_to_find_info(Path(file))\n",
    "temp_file\n",
    "# print(len(res))\n",
    "# for df in res:\n",
    "#     print(df.iloc[0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \\t ']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_headers(filename: str) -> list[str]: #filename:docx\n",
    "\n",
    "        doc = docx2python(filename)\n",
    "\n",
    "        table_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|должность)'\n",
    "\n",
    "        offices = []\n",
    "        gathering_office_info = ''\n",
    "\n",
    "        for paragraph in doc.body_runs: #параграфы в виде вложенных листов\n",
    "\n",
    "            paragraph = sum(sum(paragraph, []), [])\n",
    "            paragraph_text = ''\n",
    "            for e in paragraph:\n",
    "                try:\n",
    "                    paragraph_text += ' ' + e[0] + ' '\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            \n",
    "            paragraph_text = paragraph_text.lower()\n",
    "            its_table = re.findall(pattern=table_pattern, string=paragraph_text)\n",
    "            \n",
    "            if not its_table:\n",
    "                gathering_office_info+=paragraph_text\n",
    "            \n",
    "            elif its_table:\n",
    "                offices.append(gathering_office_info)\n",
    "                gathering_office_info=''\n",
    "\n",
    "        return [e for e in offices if e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка!\n",
      " \t \n",
      "===\n",
      " № \n",
      "п/п   Наименование должности   ФИО   Среднемесячная \n",
      "заработная плата, руб.   1   Ректор   Федорук Михаил Петрович   495 048,0   2   Первый проректор - проректор по финансово-экономической и \n",
      "инновационной деятельности   Голушко Сергей Кузьмич   324 989,0   3   Проректор по учебной работе   Саблина Светлана Геннадьевна   295 871,0   4   Проректор по научно-исследовательской деятельности   Чуркин Дмитрий Владимирович   378 002,0   5   Проректор по программам развития   Окунев Алексей Григорьевич   311 220,0   6   Проректор по общим вопросам   Малиновский Сергей Игоревич   307 303,0   7   Главный бухгалтер    Тарских Надежда Алексеевна   317 370,0  \n",
      "===\n",
      "Ошибка!\n",
      "\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_headers(doc_file):\n",
    "\n",
    "    doc = docx2python(doc_file)\n",
    "\n",
    "    table_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|должность)'\n",
    "\n",
    "    offices = []\n",
    "    gathering_office_info = ''\n",
    "\n",
    "    for paragraph in doc.body_runs: #параграфы в виде вложенных листов\n",
    "\n",
    "        paragraph = sum(sum(paragraph, []), [])\n",
    "        paragraph_text = ''\n",
    "        for e in paragraph:\n",
    "            try:\n",
    "                paragraph_text += ' ' + e[0] + ' '\n",
    "            except IndexError:\n",
    "                pass\n",
    "        \n",
    "        paragraph_text = paragraph_text.lower()\n",
    "        its_table = re.findall(pattern=table_pattern, string=paragraph_text)\n",
    "        print(paragraph_text)\n",
    "        print('===')\n",
    "        if not its_table:\n",
    "            gathering_office_info+=paragraph_text\n",
    "        \n",
    "        elif its_table:\n",
    "            offices.append(gathering_office_info)\n",
    "            gathering_office_info=''\n",
    "\n",
    "    return offices\n",
    "\n",
    "# doc_file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\для_которых_нужен_перевод_в_ворд\\temp_to_delete_89001_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx\"\n",
    "doc_file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\100185_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(sport).docx\"\n",
    "doc_file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\104563_2019_Rektor,_prorektory,_glavnyi_bukhgalter.docx\"\n",
    "\n",
    "doc = docx2python(temp_file)\n",
    "for paragraph in doc.body_runs: #параграфы в виде вложенных листов\n",
    "    paragraph_text = ''\n",
    "\n",
    "    paragraph = sum(sum(paragraph, []), [])\n",
    "    for e in paragraph:\n",
    "        try:\n",
    "            paragraph_text += ' ' + e[0] + ' '\n",
    "        except IndexError:\n",
    "            print('Ошибка!')\n",
    "            \n",
    "\n",
    "    print(paragraph_text)\n",
    "    print('===')\n",
    "\n",
    "# paragraph_text\n",
    "\n",
    "# offices = get_headers(temp_file)\n",
    "# offices\n",
    "\n",
    "# len([e for e in offices if e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\t', '\\t', '\\t', 'ИНФОРМАЦИЯ \\nо  среднемесячной заработной плате ректора, проректоров и главного бухгалтера федерального государственного автономного образовательного учреждения ', '\\t', 'высшего образования «Новосибирский национальный исследовательский государственный университет» \\n', '\\t', ' за период с 1 января 2019г. по 31 декабря 2019г. ']\n",
      " \t \n",
      "==\n",
      "['№ \\nп/п ']\n",
      "['Наименование должности ']\n",
      "['ФИО ']\n",
      "['Среднемесячная \\nзаработная плата, руб. ']\n",
      "['1 ']\n",
      "['Ректор ']\n",
      "['Федорук Михаил Петрович ']\n",
      "['495 048,0 ']\n",
      "['2 ']\n",
      "['Первый проректор - проректор по финансово-экономической и \\nинновационной деятельности ']\n",
      "['Голушко Сергей Кузьмич ']\n",
      "['324 989,0 ']\n",
      "['3 ']\n",
      "['Проректор по учебной работе ']\n",
      "['Саблина Светлана Геннадьевна ']\n",
      "['295 871,0 ']\n",
      "['4 ']\n",
      "['Проректор по научно-исследовательской деятельности ']\n",
      "['Чуркин Дмитрий Владимирович ']\n",
      "['378 002,0 ']\n",
      "['5 ']\n",
      "['Проректор по программам развития ']\n",
      "['Окунев Алексей Григорьевич ']\n",
      "['311 220,0 ']\n",
      "['6 ']\n",
      "['Проректор по общим вопросам ']\n",
      "['Малиновский Сергей Игоревич ']\n",
      "['307 303,0 ']\n",
      "['7 ']\n",
      "['Главный бухгалтер ']\n",
      "[' Тарских Надежда Алексеевна ']\n",
      "['317 370,0 ']\n",
      " № \n",
      "п/п   Наименование должности   ФИО   Среднемесячная \n",
      "заработная плата, руб.   1   Ректор   Федорук Михаил Петрович   495 048,0   2   Первый проректор - проректор по финансово-экономической и \n",
      "инновационной деятельности   Голушко Сергей Кузьмич   324 989,0   3   Проректор по учебной работе   Саблина Светлана Геннадьевна   295 871,0   4   Проректор по научно-исследовательской деятельности   Чуркин Дмитрий Владимирович   378 002,0   5   Проректор по программам развития   Окунев Алексей Григорьевич   311 220,0   6   Проректор по общим вопросам   Малиновский Сергей Игоревич   307 303,0   7   Главный бухгалтер    Тарских Надежда Алексеевна   317 370,0  \n",
      "==\n",
      "\n",
      "==\n"
     ]
    }
   ],
   "source": [
    "temp_doc = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\temp_to_delete_104563_2019_Rektor,_prorektory,_glavnyi_bukhgalter.docx\"\n",
    "\n",
    "doc = docx2python(temp_doc)\n",
    "\n",
    "table_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|должность)'\n",
    "\n",
    "for paragraph in doc.body_runs: #параграфы в виде вложенных листов\n",
    "    paragraph = sum(sum(paragraph, []), [])\n",
    "    paragraph = [e for e in paragraph if e]\n",
    "    paragraph_text = ''\n",
    "    for e in paragraph:\n",
    "        print(e)\n",
    "        try:\n",
    "            paragraph_text += ' ' + e[0] + ' '\n",
    "        except IndexError:\n",
    "            print('ошибка!')\n",
    "\n",
    "    print(paragraph_text)\n",
    "    print('==')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] xref found: pos=b'99570'\n",
      "[INFO] read_xref_from: start=99570, token=/b'xref'\n",
      "[INFO] xref objects: {1: (None, 9, 0), 2: (None, 68, 0), 3: (None, 108, 0), 4: (None, 444, 0), 5: (None, 493, 0), 6: (None, 1180, 0), 7: (None, 2037, 0), 8: (None, 2782, 0), 9: (None, 3535, 0), 10: (None, 4330, 0), 11: (None, 5097, 0), 12: (None, 5879, 0), 13: (None, 6611, 0), 14: (None, 6754, 0), 15: (None, 6942, 0), 16: (None, 7182, 0), 17: (None, 7847, 0), 18: (None, 9710, 0), 19: (None, 9810, 0), 20: (None, 9908, 0), 21: (None, 10009, 0), 22: (None, 10115, 0)}\n",
      "[INFO] trailer: {'Size': 23, 'Root': <PDFObjRef:4>, 'Info': <PDFObjRef:2>}\n",
      "[INFO] trailer: {'Size': 23, 'Root': <PDFObjRef:4>, 'Info': <PDFObjRef:2>}\n",
      "[INFO] Pages: Kids=[<PDFObjRef:3>]\n",
      "[INFO] Page: {'Contents': [<PDFObjRef:5>, <PDFObjRef:6>, <PDFObjRef:7>, <PDFObjRef:8>, <PDFObjRef:9>, <PDFObjRef:10>, <PDFObjRef:11>, <PDFObjRef:12>], 'CropBox': [0, 0, 612.48, 842.4], 'MediaBox': [0, 0, 612.48, 842.4], 'Parent': <PDFObjRef:1>, 'Resources': {'Font': {'C0_0': <PDFObjRef:13>, 'T1_0': <PDFObjRef:18>, 'T1_1': <PDFObjRef:19>, 'T1_2': <PDFObjRef:20>, 'T1_3': <PDFObjRef:21>}, 'ProcSet': [/'PDF', /'Text', /'ImageC'], 'XObject': {'Im0': <PDFObjRef:22>}}, 'Rotate': 0, 'Type': /'Page'}\n",
      "[INFO] Processing page: <PDFPage: Resources={'Font': {'C0_0': <PDFObjRef:13>, 'T1_0': <PDFObjRef:18>, 'T1_1': <PDFObjRef:19>, 'T1_2': <PDFObjRef:20>, 'T1_3': <PDFObjRef:21>}, 'ProcSet': [/'PDF', /'Text', /'ImageC'], 'XObject': {'Im0': <PDFObjRef:22>}}, MediaBox=[0, 0, 612.48, 842.4]>\n",
      "[INFO] render_contents: resources={'Font': {'C0_0': <PDFObjRef:13>, 'T1_0': <PDFObjRef:18>, 'T1_1': <PDFObjRef:19>, 'T1_2': <PDFObjRef:20>, 'T1_3': <PDFObjRef:21>}, 'ProcSet': [/'PDF', /'Text', /'ImageC'], 'XObject': {'Im0': <PDFObjRef:22>}}, streams=[<PDFObjRef:5>, <PDFObjRef:6>, <PDFObjRef:7>, <PDFObjRef:8>, <PDFObjRef:9>, <PDFObjRef:10>, <PDFObjRef:11>, <PDFObjRef:12>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "[INFO] get_font: create: objid=13, spec={'BaseFont': /'HiddenHorzOCR', 'DescendantFonts': [<PDFObjRef:14>], 'Encoding': /'Identity-H', 'Subtype': /'Type0', 'ToUnicode': <PDFObjRef:17>, 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=None, spec={'BaseFont': /'HiddenHorzOCR', 'CIDSystemInfo': {'Ordering': b'Identity', 'Registry': b'Adobe', 'Supplement': 0}, 'DW': 1000, 'FontDescriptor': <PDFObjRef:15>, 'Subtype': /'CIDFontType0', 'Type': /'Font', 'Encoding': /'Identity-H', 'ToUnicode': <PDFStream(17): raw=1790, {'Filter': /'FlateDecode', 'Length': 1789}>}\n",
      "[INFO] get_font: create: objid=18, spec={'BaseFont': /'Times-Roman', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=19, spec={'BaseFont': /'Helvetica', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=20, spec={'BaseFont': /'Times-Italic', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=21, spec={'BaseFont': /'Helvetica-Oblique', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] Processing xobj: <PDFStream(22): raw=89284, {'BitsPerComponent': 8, 'ColorSpace': /'DeviceRGB', 'Filter': /'DCTDecode', 'Height': 1755, 'Subtype': /'Image', 'Type': /'XObject', 'Width': 1276, 'Length': 89283}>\n",
      "[INFO] xref found: pos=b'99570'\n",
      "[INFO] read_xref_from: start=99570, token=/b'xref'\n",
      "[INFO] xref objects: {1: (None, 9, 0), 2: (None, 68, 0), 3: (None, 108, 0), 4: (None, 444, 0), 5: (None, 493, 0), 6: (None, 1180, 0), 7: (None, 2037, 0), 8: (None, 2782, 0), 9: (None, 3535, 0), 10: (None, 4330, 0), 11: (None, 5097, 0), 12: (None, 5879, 0), 13: (None, 6611, 0), 14: (None, 6754, 0), 15: (None, 6942, 0), 16: (None, 7182, 0), 17: (None, 7847, 0), 18: (None, 9710, 0), 19: (None, 9810, 0), 20: (None, 9908, 0), 21: (None, 10009, 0), 22: (None, 10115, 0)}\n",
      "[INFO] trailer: {'Size': 23, 'Root': <PDFObjRef:4>, 'Info': <PDFObjRef:2>}\n",
      "[INFO] trailer: {'Size': 23, 'Root': <PDFObjRef:4>, 'Info': <PDFObjRef:2>}\n",
      "[INFO] Pages: Kids=[<PDFObjRef:3>]\n",
      "[INFO] Page: {'Contents': [<PDFObjRef:5>, <PDFObjRef:6>, <PDFObjRef:7>, <PDFObjRef:8>, <PDFObjRef:9>, <PDFObjRef:10>, <PDFObjRef:11>, <PDFObjRef:12>], 'CropBox': [0, 0, 612.48, 842.4], 'MediaBox': [0, 0, 612.48, 842.4], 'Parent': <PDFObjRef:1>, 'Resources': {'Font': {'C0_0': <PDFObjRef:13>, 'T1_0': <PDFObjRef:18>, 'T1_1': <PDFObjRef:19>, 'T1_2': <PDFObjRef:20>, 'T1_3': <PDFObjRef:21>}, 'ProcSet': [/'PDF', /'Text', /'ImageC'], 'XObject': {'Im0': <PDFObjRef:22>}}, 'Rotate': 0, 'Type': /'Page'}\n",
      "[INFO] Processing page: <PDFPage: Resources={'Font': {'C0_0': <PDFObjRef:13>, 'T1_0': <PDFObjRef:18>, 'T1_1': <PDFObjRef:19>, 'T1_2': <PDFObjRef:20>, 'T1_3': <PDFObjRef:21>}, 'ProcSet': [/'PDF', /'Text', /'ImageC'], 'XObject': {'Im0': <PDFObjRef:22>}}, MediaBox=[0, 0, 612.48, 842.4]>\n",
      "[INFO] render_contents: resources={'Font': {'C0_0': <PDFObjRef:13>, 'T1_0': <PDFObjRef:18>, 'T1_1': <PDFObjRef:19>, 'T1_2': <PDFObjRef:20>, 'T1_3': <PDFObjRef:21>}, 'ProcSet': [/'PDF', /'Text', /'ImageC'], 'XObject': {'Im0': <PDFObjRef:22>}}, streams=[<PDFObjRef:5>, <PDFObjRef:6>, <PDFObjRef:7>, <PDFObjRef:8>, <PDFObjRef:9>, <PDFObjRef:10>, <PDFObjRef:11>, <PDFObjRef:12>], ctm=(1, 0, 0, 1, 0, 0)\n",
      "[INFO] get_font: create: objid=13, spec={'BaseFont': /'HiddenHorzOCR', 'DescendantFonts': [<PDFObjRef:14>], 'Encoding': /'Identity-H', 'Subtype': /'Type0', 'ToUnicode': <PDFObjRef:17>, 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=None, spec={'BaseFont': /'HiddenHorzOCR', 'CIDSystemInfo': {'Ordering': b'Identity', 'Registry': b'Adobe', 'Supplement': 0}, 'DW': 1000, 'FontDescriptor': <PDFObjRef:15>, 'Subtype': /'CIDFontType0', 'Type': /'Font', 'Encoding': /'Identity-H', 'ToUnicode': <PDFStream(17): raw=1790, {'Filter': /'FlateDecode', 'Length': 1789}>}\n",
      "[INFO] get_font: create: objid=18, spec={'BaseFont': /'Times-Roman', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=19, spec={'BaseFont': /'Helvetica', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=20, spec={'BaseFont': /'Times-Italic', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] get_font: create: objid=21, spec={'BaseFont': /'Helvetica-Oblique', 'Encoding': /'WinAnsiEncoding', 'Subtype': /'Type1', 'Type': /'Font'}\n",
      "[INFO] Processing xobj: <PDFStream(22): raw=89284, {'BitsPerComponent': 8, 'ColorSpace': /'DeviceRGB', 'Filter': /'DCTDecode', 'Height': 1755, 'Subtype': /'Image', 'Type': /'XObject', 'Width': 1276, 'Length': 89283}>\n",
      "2022-03-16T16:21:35 - INFO - Processing page-1\n",
      "[INFO] Processing page-1\n"
     ]
    }
   ],
   "source": [
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\104649_2019_Rektor,_prorektory,_glavnyi_bukhgalter.pdf\"\n",
    "incor_parser = IncorrectHeaders()\n",
    "pdf_parser = PdfParser()\n",
    "df = pdf_parser.convert_pdf_to_df(file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "2. придумать, как объединять таблицы на разных страницах.\n",
    "\n",
    "'''\n",
    "\n",
    "def drop_col_with_N(df:pd.DataFrame):\n",
    "    expr = '(№|п/п)'\n",
    "    for c in df.columns:\n",
    "        if re.search(expr, c):\n",
    "            df.drop(columns=c, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_short_cols(df: pd.DataFrame):\n",
    "    len_df = df.applymap(len)\n",
    "    for c in df.columns:\n",
    "        if len_df[c].mean() < 4:\n",
    "            df.drop(columns=c, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>№ \\nп/п</th>\n",
       "      <th>ФИО</th>\n",
       "      <th>Должность</th>\n",
       "      <th>Среднемесячная заработная \\nплата за 2019 год (руб.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>№ \\nп/п</td>\n",
       "      <td>ФИО</td>\n",
       "      <td>Должность</td>\n",
       "      <td>Среднемесячная заработная \\nплата за 2019 год ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>Старинцева Оксана \\nГульвариевна</td>\n",
       "      <td>Директор муниципального \\nучреждения «Районный...</td>\n",
       "      <td>74357,52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>Шахназарян Татьяна \\nМихайловна</td>\n",
       "      <td>Директор муниципального \\nучреждения культуры ...</td>\n",
       "      <td>44323,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>Сачко Ирина Юрьевна</td>\n",
       "      <td>Директор муниципального \\nучреждения культуры ...</td>\n",
       "      <td>54180,36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>Лисаченко Зоя \\nВладимировна</td>\n",
       "      <td>Директор бюджетного \\nучреждения дополнительно...</td>\n",
       "      <td>45651,44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.</td>\n",
       "      <td>Семерижная Любовь \\nИвановна</td>\n",
       "      <td>Директор муниципального \\nучреждения «Районный...</td>\n",
       "      <td>51046,40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.</td>\n",
       "      <td>Коваленко Татьяна \\nПавловна</td>\n",
       "      <td>Директор муниципального \\nучреждения «Районный...</td>\n",
       "      <td>41884,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>Ладыко Лидия Николаевна</td>\n",
       "      <td>главный бухгалтер \\nмуниципального учреждения ...</td>\n",
       "      <td>49976,55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.</td>\n",
       "      <td>Миронова Елена \\nВалерьевна</td>\n",
       "      <td>главный бухгалтер \\nмуниципального учреждения ...</td>\n",
       "      <td>35555,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.</td>\n",
       "      <td>Бондаренко Марина \\nВикторовна</td>\n",
       "      <td>Г лавный бухгалтер бюджетного \\nучреждения доп...</td>\n",
       "      <td>40507,35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>образования «Детская школа \\nискусств»</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.</td>\n",
       "      <td>Смирнова Светлана \\nАнатольевна</td>\n",
       "      <td>главный бухгалтер \\nмуниципального учреждения ...</td>\n",
       "      <td>32902,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.</td>\n",
       "      <td>Чебан Сергей Иванович</td>\n",
       "      <td>заместитель директора по \\nхозяйственной части...</td>\n",
       "      <td>52862,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.</td>\n",
       "      <td>Лозина Надежда \\nАнатольевна</td>\n",
       "      <td>Заместитель директора по \\nучебной части муниц...</td>\n",
       "      <td>31832,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.</td>\n",
       "      <td>Котченко Виктор \\nВладимирович</td>\n",
       "      <td>Заместитель директора по АХЧ \\nмуниципального ...</td>\n",
       "      <td>35329,22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  № \\nп/п                               ФИО  \\\n",
       "0  № \\nп/п                               ФИО   \n",
       "1       1.  Старинцева Оксана \\nГульвариевна   \n",
       "2       2.   Шахназарян Татьяна \\nМихайловна   \n",
       "3       3.               Сачко Ирина Юрьевна   \n",
       "4       4.      Лисаченко Зоя \\nВладимировна   \n",
       "5       5.      Семерижная Любовь \\nИвановна   \n",
       "6       6.      Коваленко Татьяна \\nПавловна   \n",
       "7       7.           Ладыко Лидия Николаевна   \n",
       "8       8.       Миронова Елена \\nВалерьевна   \n",
       "9       9.    Бондаренко Марина \\nВикторовна   \n",
       "0                                              \n",
       "1      10.   Смирнова Светлана \\nАнатольевна   \n",
       "2      11.             Чебан Сергей Иванович   \n",
       "3      12.      Лозина Надежда \\nАнатольевна   \n",
       "4      13.    Котченко Виктор \\nВладимирович   \n",
       "\n",
       "0                                          Должность  \\\n",
       "0                                          Должность   \n",
       "1  Директор муниципального \\nучреждения «Районный...   \n",
       "2  Директор муниципального \\nучреждения культуры ...   \n",
       "3  Директор муниципального \\nучреждения культуры ...   \n",
       "4  Директор бюджетного \\nучреждения дополнительно...   \n",
       "5  Директор муниципального \\nучреждения «Районный...   \n",
       "6  Директор муниципального \\nучреждения «Районный...   \n",
       "7  главный бухгалтер \\nмуниципального учреждения ...   \n",
       "8  главный бухгалтер \\nмуниципального учреждения ...   \n",
       "9  Г лавный бухгалтер бюджетного \\nучреждения доп...   \n",
       "0             образования «Детская школа \\nискусств»   \n",
       "1  главный бухгалтер \\nмуниципального учреждения ...   \n",
       "2  заместитель директора по \\nхозяйственной части...   \n",
       "3  Заместитель директора по \\nучебной части муниц...   \n",
       "4  Заместитель директора по АХЧ \\nмуниципального ...   \n",
       "\n",
       "0 Среднемесячная заработная \\nплата за 2019 год (руб.)  \n",
       "0  Среднемесячная заработная \\nплата за 2019 год ...    \n",
       "1                                           74357,52    \n",
       "2                                            44323,2    \n",
       "3                                           54180,36    \n",
       "4                                           45651,44    \n",
       "5                                           51046,40    \n",
       "6                                           41884,03    \n",
       "7                                           49976,55    \n",
       "8                                           35555,00    \n",
       "9                                           40507,35    \n",
       "0                                                       \n",
       "1                                           32902,72    \n",
       "2                                           52862,41    \n",
       "3                                           31832,05    \n",
       "4                                           35329,22    "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\converted\\177695_2020_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.pdf\"\n",
    "file = r\"D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\pdf\\101640_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(kul'tura).pdf\"\n",
    "\n",
    "# dfs = incor_parser.convert_pdf_to_df_and_find_tables(file)\n",
    "# dfs[0]\n",
    "#dfs = pdf_parser.convert_pdf_to_df(file)\n",
    "\n",
    "#\n",
    "\"\"\"\n",
    "есть список таблиц. \n",
    "если у первой таблицы найдены заголовки\n",
    "а у других таблиц нет - присовокупляем все к первой\n",
    "\n",
    "\"\"\"\n",
    "list_of_dfs = []\n",
    "my_hash = {\n",
    "    'ok_df':True, 'ne_ok_df':False\n",
    "}\n",
    "correct = False\n",
    "df_to_concat = ''\n",
    "\n",
    "\n",
    "# если на этом этапе колонки не найдены. то таблицу - в топку\n",
    "\n",
    "all_oks = my_hash.values()\n",
    "if all(all_oks) or not all(all_oks):\n",
    "    print('дропаем')\n",
    "\n",
    "\n",
    "for df, ok_cols in my_hash.items():\n",
    "    if ok_cols:\n",
    "        df_to_concat = df\n",
    "    elif not ok_cols and df_to_concat:\n",
    "        print('КОНКАТИНИРУЕМ')\n",
    "\n",
    "\n",
    "# ok_df = incor_parser.find_ok_cols(dfs[0])\n",
    "# ne_ok = dfs[1]\n",
    "# ne_ok.columns = ok_df.columns\n",
    "# pd.concat([ok_df,ne_ok])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [False, False]\n",
    "\n",
    "not all(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>образования «Детская школа \\nискусств»</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.</td>\n",
       "      <td>Смирнова Светлана \\nАнатольевна</td>\n",
       "      <td>главный бухгалтер \\nмуниципального учреждения ...</td>\n",
       "      <td>32902,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.</td>\n",
       "      <td>Чебан Сергей Иванович</td>\n",
       "      <td>заместитель директора по \\nхозяйственной части...</td>\n",
       "      <td>52862,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.</td>\n",
       "      <td>Лозина Надежда \\nАнатольевна</td>\n",
       "      <td>Заместитель директора по \\nучебной части муниц...</td>\n",
       "      <td>31832,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13.</td>\n",
       "      <td>Котченко Виктор \\nВладимирович</td>\n",
       "      <td>Заместитель директора по АХЧ \\nмуниципального ...</td>\n",
       "      <td>35329,22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    0                                1  \\\n",
       "0      0                                         \n",
       "1      1  10.  Смирнова Светлана \\nАнатольевна   \n",
       "2      2  11.            Чебан Сергей Иванович   \n",
       "3      3  12.     Лозина Надежда \\nАнатольевна   \n",
       "4      4  13.   Котченко Виктор \\nВладимирович   \n",
       "\n",
       "                                                   2         3  \n",
       "0             образования «Детская школа \\nискусств»            \n",
       "1  главный бухгалтер \\nмуниципального учреждения ...  32902,72  \n",
       "2  заместитель директора по \\nхозяйственной части...  52862,41  \n",
       "3  Заместитель директора по \\nучебной части муниц...  31832,05  \n",
       "4  Заместитель директора по АХЧ \\nмуниципального ...  35329,22  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137dc9a7529e050f0d3404627e217fd4120b6229f927507e6c7e6283ad4b3698"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
