{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1b0bbdc6-a22f-42b0-80f2-50d15f8f0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "from typing import Union\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "import typing\n",
    "import io\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "import camelot\n",
    "\n",
    "import pandas as pd\n",
    "%config Completer.use_jedi = False\n",
    "from pathlib import Path\n",
    "# import tqdm.notebook.tqdm as tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "# from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc265770-b9db-4945-954d-46551590d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_docx_tables(filename, tab_id=None, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    parse table(s) fromt.columnsrd Document (.docx) into Pandas DataFrame(s)\n",
    "\n",
    "    Parameters:\n",
    "        filename:   file name of a Word Document\n",
    "\n",
    "        tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                    When [None] - return a list of DataFrames (parse all tables)\n",
    "\n",
    "        kwargs:     arguments to pass to `pd.read_csv()` function\n",
    "\n",
    "    Return: a single DataFrame if tab_id != None or a list of DataFrames otherwise\n",
    "    \"\"\"\n",
    "    def read_docx_tab(tab, **kwargs):\n",
    "        vf = io.StringIO()\n",
    "        writer = csv.writer(vf)\n",
    "        for row in tab.rows:\n",
    "            writer.writerow(cell.text for cell in row.cells)\n",
    "        vf.seek(0)\n",
    "        return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "    doc = Document(filename)\n",
    "    if tab_id is None:\n",
    "        return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "    else:\n",
    "        try:\n",
    "            return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "        except IndexError:\n",
    "            print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "            raise\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def rename_col(col):\n",
    "    col = col.lower()\n",
    "    if re.search(pattern='(фамилия|имя|фио|ф.и.о.|отчество)', string=col):\n",
    "        return \"ФИО\"\n",
    "\n",
    "    elif re.search(pattern='(заработная плата|cреднемесячная|зарпл.)', string=col):\n",
    "        return \"Зарплата\"\n",
    "\n",
    "    elif re.search(pattern='(должност[и,ь])', string=col):\n",
    "        return 'Должность'\n",
    "\n",
    "    elif re.search(pattern='(предприяти[е,я]|учреждени[е,я]|юридическое лицо)', string=col):\n",
    "        return 'Учреждение'\n",
    "\n",
    "    \n",
    "    return col\n",
    "\n",
    "\n",
    "def check_if_columns_ok(cols: tuple) -> bool:\n",
    "    cols = list(map(str, cols))\n",
    "    cols = list(map(str.lower, cols))\n",
    "    one_already_found = False \n",
    "    pattern = '(фамилия|имя|фио|ф.и.о|отчество|заработная плата|cреднемесячная|зарпл|занимаемая|должност[и,ь]|(предприяти[е,я]|учреждени[е,я]))'\n",
    "    \n",
    "    for col in cols:\n",
    "        res = re.search(pattern=pattern, string=col)\n",
    "        if res and not one_already_found:\n",
    "            one_already_found = True\n",
    "        elif res and one_already_found:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "    \n",
    "def detect_and_rename_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    cols = df.columns\n",
    "    res = check_if_columns_ok(cols)\n",
    "\n",
    "    if not res:        \n",
    "        for index, cell in enumerate(df[:3].itertuples()):\n",
    "            res = check_if_columns_ok(cell)\n",
    "            if res:\n",
    "                df.columns = df.iloc[index]\n",
    "                df = df[index+1:]\n",
    "                break\n",
    "        if not res:\n",
    "            return False, df\n",
    "            #raise ValueError('заголовки колонок не найдены')\n",
    "\n",
    "    cols = df.columns\n",
    "    renamed_cols = []\n",
    "    for col in cols:\n",
    "        renamed_cols.append(rename_col(col))\n",
    "\n",
    "    df.columns = renamed_cols\n",
    "    return True, df\n",
    "\n",
    "\n",
    "def read_all_docs()->list[dict[str, Document]]:\n",
    "    all_docs = []\n",
    "    for doc in os.listdir(folder):\n",
    "        if not doc.endswith('docx'):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            all_docs.append({'file':doc,'doc':Document(folder + doc)})\n",
    "        except:\n",
    "            print('не вышло--', doc)\n",
    "    \n",
    "    return all_docs\n",
    "\n",
    "def get_all_tables(all_docs: list[dict]) -> list[pd.DataFrame]:\n",
    "    all_tables = []\n",
    "    for doc_dict in all_docs:\n",
    "        tables = read_docx_tables(folder + doc_dict['file'])        \n",
    "        all_tables.append(tables)\n",
    "\n",
    "    return all_tables\n",
    "\n",
    "#all_docs = read_all_docs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncorrectHeaders:\n",
    "    \"\"\"класс для таблиц с неопределенными заголовками\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def search_for_office(df: pd.DataFrame):\n",
    "        # ищет названия учреждени внутри таблицы \n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def parse(self, df: pd.DataFrame) -> typing.Union[pd.DataFrame, False]:\n",
    "        df = self.search_for_office(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # если учреждения не нашли, \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70bcd165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "зашли в проверку колонок --- ['полное наименование учреждения или\\nпредприятия', 'должность', 'фио (полностью)', 'среднемесячная заработная плата\\n(руб.)']\n",
      "columns_ok---- True\n",
      "col before rename cols -- Полное наименование учреждения или\n",
      "предприятия\n",
      "col before rename cols -- Должность\n",
      "col before rename cols -- ФИО (полностью)\n",
      "col before rename cols -- Среднемесячная заработная плата\n",
      "(руб.)\n",
      "зашли в проверку колонок --- ['полное наименование учреждения или\\nпредприятия', 'должность', 'фио (полностью)', 'среднемесячная заработная плата\\n(руб.)']\n",
      "columns_ok---- True\n",
      "col before rename cols -- Полное наименование учреждения или\n",
      "предприятия\n",
      "col before rename cols -- Должность\n",
      "col before rename cols -- ФИО (полностью)\n",
      "col before rename cols -- Среднемесячная заработная плата\n",
      "(руб.)\n",
      "зашли в проверку колонок --- ['полное наименование учреждения или\\nпредприятия', 'должность', 'фио (полностью)', 'среднемесячная заработная плата\\n(руб.)']\n",
      "columns_ok---- True\n",
      "col before rename cols -- Полное наименование учреждения или\n",
      "предприятия\n",
      "col before rename cols -- Должность\n",
      "col before rename cols -- ФИО (полностью)\n",
      "col before rename cols -- Среднемесячная заработная плата\n",
      "(руб.)\n",
      "зашли в проверку колонок --- ['полное наименование учреждения или\\nпредприятия', 'должность', 'фио (полностью)', 'среднемесячная заработная плата\\n(руб.)']\n",
      "columns_ok---- True\n",
      "col before rename cols -- Полное наименование учреждения или\n",
      "предприятия\n",
      "col before rename cols -- Должность\n",
      "col before rename cols -- ФИО (полностью)\n",
      "col before rename cols -- Среднемесячная заработная плата\n",
      "(руб.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Баринов Геннадий Иванович</td>\n",
       "      <td>Начальник</td>\n",
       "      <td>Федеральное казенное учреждение «Объект № 5068...</td>\n",
       "      <td>21282,91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Субботина Любовь Михайловна</td>\n",
       "      <td>Главный бухгалтер (с 01.01.2016 по 15.08.2016)</td>\n",
       "      <td>Федеральное казенное учреждение «Объект № 5068...</td>\n",
       "      <td>25752,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Онучина Елена Витальевна</td>\n",
       "      <td>Главный бухгалтер (с 16.08.2016 по 31.12.2016)</td>\n",
       "      <td>Федеральное казенное учреждение «Объект № 5068...</td>\n",
       "      <td>18904, 74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Рыбак Олег Павлович</td>\n",
       "      <td>Директор</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>93652,92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Фролова Наталья Борисовна</td>\n",
       "      <td>Главный бухгалтер</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>32733,28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное бюджетное учрежден...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Пряхина Елена</td>\n",
       "      <td>Директор</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>230837,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Владимировна</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Сладкова Ирина Сергеевна</td>\n",
       "      <td>Заместитель директора</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>99579,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Гусенкова Елена Васильевна</td>\n",
       "      <td>Главный бухгалтер</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>79732,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Федеральное государственное унитарное предприя...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Котик Виктор Николаевич</td>\n",
       "      <td>Врио директора (с 01.01.2016 по 07.11.2016</td>\n",
       "      <td>Федеральное государственной унитарное предприя...</td>\n",
       "      <td>46250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Дмитричев Вадим Александрович</td>\n",
       "      <td>Директор (с 08.11.2016 по 31.12.2016)</td>\n",
       "      <td>Федеральное государственной унитарное предприя...</td>\n",
       "      <td>46250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Котик Виктор Николаевич</td>\n",
       "      <td>Заместитель директора</td>\n",
       "      <td>Федеральное государственной унитарное предприя...</td>\n",
       "      <td>46050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кузнецова Екатерина Владимировна</td>\n",
       "      <td>Главный бухгалтер</td>\n",
       "      <td>Федеральное государственной унитарное предприя...</td>\n",
       "      <td>46000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name  \\\n",
       "1          Баринов Геннадий Иванович   \n",
       "2        Субботина Любовь Михайловна   \n",
       "3           Онучина Елена Витальевна   \n",
       "1                Рыбак Олег Павлович   \n",
       "2                                nan   \n",
       "3                                nan   \n",
       "4                                nan   \n",
       "5          Фролова Наталья Борисовна   \n",
       "6                                nan   \n",
       "7                                nan   \n",
       "8                                nan   \n",
       "9                                nan   \n",
       "10                               nan   \n",
       "1                      Пряхина Елена   \n",
       "2                       Владимировна   \n",
       "3                                nan   \n",
       "4                                nan   \n",
       "5           Сладкова Ирина Сергеевна   \n",
       "6                                nan   \n",
       "7                                nan   \n",
       "8                                nan   \n",
       "9         Гусенкова Елена Васильевна   \n",
       "10                               nan   \n",
       "1            Котик Виктор Николаевич   \n",
       "2      Дмитричев Вадим Александрович   \n",
       "3            Котик Виктор Николаевич   \n",
       "4   Кузнецова Екатерина Владимировна   \n",
       "\n",
       "                                          position  \\\n",
       "1                                        Начальник   \n",
       "2   Главный бухгалтер (с 01.01.2016 по 15.08.2016)   \n",
       "3   Главный бухгалтер (с 16.08.2016 по 31.12.2016)   \n",
       "1                                         Директор   \n",
       "2                                              nan   \n",
       "3                                              nan   \n",
       "4                                              nan   \n",
       "5                                Главный бухгалтер   \n",
       "6                                              nan   \n",
       "7                                              nan   \n",
       "8                                              nan   \n",
       "9                                              nan   \n",
       "10                                             nan   \n",
       "1                                         Директор   \n",
       "2                                              nan   \n",
       "3                                              nan   \n",
       "4                                              nan   \n",
       "5                            Заместитель директора   \n",
       "6                                              nan   \n",
       "7                                              nan   \n",
       "8                                              nan   \n",
       "9                                Главный бухгалтер   \n",
       "10                                             nan   \n",
       "1       Врио директора (с 01.01.2016 по 07.11.2016   \n",
       "2            Директор (с 08.11.2016 по 31.12.2016)   \n",
       "3                            Заместитель директора   \n",
       "4                                Главный бухгалтер   \n",
       "\n",
       "                                           department     salary  \n",
       "1   Федеральное казенное учреждение «Объект № 5068...   21282,91  \n",
       "2   Федеральное казенное учреждение «Объект № 5068...   25752,13  \n",
       "3   Федеральное казенное учреждение «Объект № 5068...  18904, 74  \n",
       "1   Федеральное государственное бюджетное учрежден...   93652,92  \n",
       "2   Федеральное государственное бюджетное учрежден...        nan  \n",
       "3   Федеральное государственное бюджетное учрежден...        nan  \n",
       "4   Федеральное государственное бюджетное учрежден...        nan  \n",
       "5   Федеральное государственное бюджетное учрежден...   32733,28  \n",
       "6   Федеральное государственное бюджетное учрежден...        nan  \n",
       "7   Федеральное государственное бюджетное учрежден...        nan  \n",
       "8   Федеральное государственное бюджетное учрежден...        nan  \n",
       "9   Федеральное государственное бюджетное учрежден...        nan  \n",
       "10  Федеральное государственное бюджетное учрежден...        nan  \n",
       "1   Федеральное государственное унитарное предприя...  230837,00  \n",
       "2   Федеральное государственное унитарное предприя...        nan  \n",
       "3   Федеральное государственное унитарное предприя...        nan  \n",
       "4   Федеральное государственное унитарное предприя...        nan  \n",
       "5   Федеральное государственное унитарное предприя...   99579,00  \n",
       "6   Федеральное государственное унитарное предприя...        nan  \n",
       "7   Федеральное государственное унитарное предприя...        nan  \n",
       "8   Федеральное государственное унитарное предприя...        nan  \n",
       "9   Федеральное государственное унитарное предприя...   79732,00  \n",
       "10  Федеральное государственное унитарное предприя...        nan  \n",
       "1   Федеральное государственной унитарное предприя...      46250  \n",
       "2   Федеральное государственной унитарное предприя...      46250  \n",
       "3   Федеральное государственной унитарное предприя...      46050  \n",
       "4   Федеральное государственной унитарное предприя...      46000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "folder = 'data_ids/docx/'\n",
    "\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\"убирает лишние данные\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_unwanted_symbols(df):        \n",
    "        # TODO: чистка всех колонок\n",
    "        df = df.applymap(lambda x: str(x).replace('\\n', ' '))\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_unwanted_cells(df):\n",
    "        # убирает ячейки с нумерацией\n",
    "        # print('--- DataCleaner.remove_unwanted_cells ---', df.columns)\n",
    "        df = df[~df['position'].astype(str).str.isdigit()]\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_short_rows(df):\n",
    "        # удаляет ряды с недостаточными данными\n",
    "        # ! должно применяться после выбора норм колонок\n",
    "        to_remove = []\n",
    "        for tup in df.itertuples():\n",
    "            res = [len(str(e)) for e in tup]\n",
    "            if statistics.mean(res) > 5:\n",
    "                to_remove.append(tup.Index)\n",
    "        \n",
    "        df.drop(to_remove, inplace=True)\n",
    "        return df\n",
    "             \n",
    "\n",
    "    def clean_df(self, df):\n",
    "        df = self.remove_unwanted_symbols(df)\n",
    "        df = self.remove_unwanted_cells(df)\n",
    "        df = self.remove_short_rows(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "class CorrectHeadersParser:\n",
    "\n",
    "    '''класс для парсинга таблиц, у которых на месте колонки, которые нам нужны'''\n",
    "\n",
    "    def table_splitter(self, table: pd.DataFrame, file_name) -> list[pd.DataFrame]:\n",
    "        '''разделяет таблицы, в которых учреждение указано внутри таблицы'''\n",
    "\n",
    "        def check_if_same(my_array: list) -> bool:\n",
    "            \n",
    "            '''проверяем одинаковые ли колонки'''\n",
    "\n",
    "            first = my_array[0]\n",
    "            for e in my_array[1:]:\n",
    "                if e != first:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        def get_indexes_to_split(table):\n",
    "            index_to_split = []\n",
    "            for e in range(len(table)):\n",
    "                cols = table.iloc[e,:].values\n",
    "                if check_if_same(cols):\n",
    "                    index_to_split.append(e)\n",
    "            return index_to_split\n",
    "\n",
    "\n",
    "        def split_table(table: pd.DataFrame, index_to_split:Union[int, list[int]], file_name) -> list[pd.DataFrame]:\n",
    "            dfs = np.array_split(table, index_to_split)\n",
    "            dfs = [e for e in dfs if len(e) > 0]\n",
    "\n",
    "            result_dfs = []\n",
    "            for df in dfs:\n",
    "                office = df.iloc[0,:][0]\n",
    "                df = df.iloc[1:,:] \n",
    "                df['office'] = office\n",
    "                result_dfs.append(df)\n",
    "            \n",
    "            result_dfs = [e for e in result_dfs if not e.empty]\n",
    "            try:\n",
    "                result_dfs = pd.concat(result_dfs)\n",
    "                return result_dfs\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print('rogue file---', file_name)\n",
    "                \n",
    "        index_to_split = get_indexes_to_split(table)\n",
    "\n",
    "        if not index_to_split:\n",
    "            return table\n",
    "\n",
    "        splitted_dfs = split_table(table, index_to_split, file_name)\n",
    "        return splitted_dfs\n",
    "\n",
    "        \n",
    "    def concat_name(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''соединяем колонки ФИО, если они в разных'''\n",
    "        \n",
    "        if 'name' not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        names_df = df['name']\n",
    "    \n",
    "        if isinstance(names_df, str) or isinstance(names_df, pd.Series):\n",
    "            return df  \n",
    "    \n",
    "        # TODO:\n",
    "        # дропнуть маленькую колонку\n",
    "\n",
    "\n",
    "        names = [' '.join(e) for e in names_df.values]     \n",
    "        \n",
    "        df.drop(columns=['name'], inplace=True)\n",
    "        df['name'] = names\n",
    "        return df\n",
    "\n",
    "\n",
    "    def parse(self, table: pd.DataFrame, file_name) -> pd.DataFrame:\n",
    "        table = self.concat_name(table)\n",
    "        table = self.table_splitter(table, file_name)\n",
    "        return table\n",
    "\n",
    "\n",
    "\n",
    "class DocxParser:\n",
    "\n",
    "    def __init__(self):\n",
    "       self.cols_we_need = ['name','salary', 'position', 'department']\n",
    "       self.parse_correct_headers = CorrectHeadersParser()\n",
    "       self.parse_incorrect_headers = ''\n",
    "       self.all_docs: list[dict[str, Document]]\n",
    "       self.data_cleaner = DataCleaner()\n",
    "       \n",
    "\n",
    "\n",
    "        \n",
    "    def read_docx_tables(self, filename, tab_id=None, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        parse table(s) fromt.columnsrd Document (.docx) into Pandas DataFrame(s)\n",
    "\n",
    "        Parameters:\n",
    "            filename:   file name of a Word Document\n",
    "\n",
    "            tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                        When [None] - return a list of DataFrames (parse all tables)\n",
    "\n",
    "            kwargs:     arguments to pass to `pd.read_csv()` function\n",
    "\n",
    "        Return: a single DataFrame if tab_id != None or a list of DataFrames otherwise\n",
    "        \"\"\"\n",
    "        def read_docx_tab(tab, **kwargs):\n",
    "            vf = io.StringIO()\n",
    "            writer = csv.writer(vf)\n",
    "            for row in tab.rows:\n",
    "                writer.writerow(cell.text for cell in row.cells)\n",
    "            vf.seek(0)\n",
    "            return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "        doc = Document(filename)\n",
    "        if tab_id is None:\n",
    "            return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "        else:\n",
    "            try:\n",
    "                return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "            except IndexError:\n",
    "                print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "                raise\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def rename_col(col: str) -> str:\n",
    "\n",
    "        print('col before rename cols --', col)\n",
    "        col = col.lower()\n",
    "        if re.search(pattern='(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество)', string=col):\n",
    "            return \"name\"\n",
    "\n",
    "        elif re.search(pattern='(cреднемесячная|зарпл.|плат[ы, а]|заработн[ой, ая] плат[а, ы]|cреднемесячн[ая, ой]|зарплат[а, ной, ы])', string=col):\n",
    "            return \"salary\"\n",
    "\n",
    "        elif re.search(pattern='(должност[ь, и, ей])', string=col): \n",
    "\n",
    "            return 'position'\n",
    "\n",
    "        elif re.search(pattern='(предприяти[е,я]|учреждени[е,я]|юридическое лицо)', string=col):\n",
    "            return 'department'\n",
    "\n",
    "        return col\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def check_if_columns_ok(cols: tuple) -> bool:\n",
    "        '''проверяем, есть ли в заголовках таблицы название предприятия и другая инфа'''\n",
    "        \n",
    "        cols = list(map(str, cols))\n",
    "        cols = list(map(str.lower, cols))\n",
    "        print('зашли в проверку колонок ---', cols)\n",
    "        ok_cols = 0\n",
    "        company_found = False\n",
    "        for col in cols:\n",
    "            company_pattern = '(предприяти[е,я]|учреждени[е,я]|юридическ[ое,ие])'\n",
    "            res = re.search(pattern=company_pattern, string=col)\n",
    "            if res:\n",
    "                company_found = True\n",
    "                continue\n",
    "            \n",
    "            name_salary_position_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|плат[ы, а]|заработная|плата|cреднемесячн[ая, ой]|зарплат[а, ной, ы]|должность|)'\n",
    "            \n",
    "            res = re.search(pattern=name_salary_position_pattern, string=col)\n",
    "            if res:\n",
    "                ok_cols+=1\n",
    "\n",
    "        if company_found and ok_cols > 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def get_all_tables_of_a_doc(self, filename: str) -> list[pd.DataFrame]:\n",
    "\n",
    "        tables = self.read_docx_tables(filename)        \n",
    "        return tables\n",
    "\n",
    "\n",
    "\n",
    "    def parse_doc(self, filename: str) -> pd.DataFrame:\n",
    "        assert filename.endswith('docx'), 'Формат должен быть .docx!'\n",
    "            \n",
    "        doc = Document(filename)\n",
    "        # тут взять текст, который потом прикрутить к\n",
    "\n",
    "        doc_tables = self.get_all_tables_of_a_doc(filename) \n",
    "        parsed_tables = []\n",
    "        i=0\n",
    "        for table in doc_tables: # в этом моменте мы отдаем df \n",
    "            i+=1\n",
    "            # print('table---', table.columns)\n",
    "            # table.to_excel(f'{i}_промежуточны_странный.xlsx')\n",
    "            \n",
    "            columns_ok = self.check_if_columns_ok(table)\n",
    "            print('columns_ok----',columns_ok)\n",
    "            if not columns_ok:\n",
    "            # пометить?\n",
    "            # если учреждения нет - смотрим параграфы. \n",
    "                # добавить документ в опущенные\n",
    "                pass\n",
    "\n",
    "            else:                \n",
    "                # если заголовки ок, оставляем только нужные\n",
    "\n",
    "                table.columns = [self.rename_col(col) for col in table.columns]\n",
    "\n",
    "                \n",
    "                cols_to_leave = [col for col in table.columns if col in self.cols_we_need]\n",
    "                cols_to_leave = set(cols_to_leave)\n",
    "                table = table[cols_to_leave]\n",
    "                \n",
    "                # проверяем на наличие вложенных таблиц и фио, разнесенных на несколько стаоблцов\n",
    "                table = self.parse_correct_headers.parse(table, filename)\n",
    "                # убираем лишние ячейки и символы\n",
    "                table = self.data_cleaner.clean_df(table)\n",
    "                parsed_tables.append(table)\n",
    "                        \n",
    "        parsed_tables = [e for e in parsed_tables if isinstance(e, pd.DataFrame) and not e.empty]\n",
    "        \n",
    "        if isinstance(parsed_tables, list):\n",
    "            if parsed_tables:\n",
    "                concat_tables = pd.concat(parsed_tables)\n",
    "                return concat_tables\n",
    "        \n",
    "        elif isinstance(parsed_tables, pd.DataFrame):\n",
    "            if not parsed_tables.empty:\n",
    "                return concat_tables\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def parse_folder(self, path: str):\n",
    "        all_tables = []\n",
    "        for doc in os.listdir(path):\n",
    "            pass \n",
    "        #for doc in self.all_docs:\n",
    "        #     tables = self.parse_doc(doc)\n",
    "        #     if tables:\n",
    "        #         # return tables\n",
    "        #         #print(tables)\n",
    "        #         # tables = pd.concat(tables)\n",
    "        #         all_tables.append({'file_name':doc, 'df':tables})\n",
    "        \n",
    "        # return all_tables\n",
    "\n",
    "class Parser:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cols_we_need = ['name','salary', 'position', 'department']\n",
    "        self.all_docs: list[str]\n",
    "  \n",
    "        self.docx_parser = ''    \n",
    "        self.pdf_parser = ''\n",
    " \n",
    "        self.parse_correct_headers = CorrectHeadersParser()     \n",
    "        self.parse_incorrect_headers = ''\n",
    "\n",
    "        self.data_cleaner = DataCleaner()\n",
    "    \n",
    "    \n",
    "class PdfParser:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def convert_pdf_to_df(filename) -> list[pd.DataFrame]:\n",
    "        tables = camelot.read_pdf(file, line_tol=2, joint_tol=10, line_scale=40, copy_text=['v'], pages='1-end') # , flavor='stream' row_tol=10\n",
    "        tables = [e.df for e in tables]\n",
    "        return tables\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "parser = DocxParser()\n",
    "# # res = parser.parse_doc(folder + file)\n",
    "# res = parser.parse_doc(folder + file)\n",
    "# folder = 'data_ids/doc/'\n",
    "\n",
    "\n",
    "# res = parser.parse_doc(folder + file)\n",
    "# res.to_excel(folder + 'cool/ok/' + file + '.xlsx')\n",
    "\n",
    "folder = 'data_ids/pdf/converted/'\n",
    "file = '189843_2020_Rukovoditeli.docx'\n",
    "file = '180480_2020_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(lesnichestva).docx'\n",
    "file = '180466_2020_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "file = '181208_2020_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "file = '178292_2020_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "file = '185859_2020_Rukovoditeli_podvedomstvennykh_uchrezhdenii.docx'\n",
    "\n",
    "\n",
    "file = '83327_2016_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "# doc = Document(folder + file)\n",
    "# for e in doc.paragraphs:\n",
    "#     print(e.text)\n",
    "#     print('===')\n",
    "\n",
    "res = parser.parse_doc(folder + file)\n",
    "res\n",
    "\n",
    "\n",
    "# errors = []\n",
    "# for doc in tqdm_notebook(os.listdir(folder)):\n",
    "#     if not doc.endswith('docx'):\n",
    "#         continue\n",
    "#     try:\n",
    "#         res = parser.parse_doc(folder + doc)    \n",
    "#         if isinstance(res, pd.DataFrame):\n",
    "#             res.to_excel(folder + 'cool/' + doc + '.xlsx' )\n",
    "\n",
    "#     except Exception as ex:\n",
    "#         errors.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfda9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd9cd1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols--- ['№ п/п', 'наименование учреждения', 'фио', 'замещаемая должность', 'среднемесячная заработная плата,\\nруб.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# incorrect headers\n",
    "# def detect_and_rename_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     '''!!!!   этот метод для парсинга неправильных заголовков'''\n",
    "    \n",
    "#     cols = df.columns\n",
    "#     res = check_if_columns_ok(cols)\n",
    "\n",
    "#     if not res:        \n",
    "#         for index, cell in enumerate(df[:3].itertuples()):\n",
    "#             res = check_if_columns_ok(cell)\n",
    "#             if res:\n",
    "#                 df.columns = df.iloc[index]\n",
    "#                 df = df[index+1:]\n",
    "#                 break\n",
    "#         if not res:\n",
    "#             return False, df\n",
    "\n",
    "#     cols = df.columns\n",
    "#     renamed_cols = []\n",
    "#     for col in cols:\n",
    "#         renamed_cols.append(rename_col(col))\n",
    "\n",
    "#     df.columns = renamed_cols\n",
    "#     return True, df\n",
    "\n",
    "# TODO: есть еще ситуация - должность и учреждение в одной ячейке. можно решить доп проверкой \n",
    "# - если в должности гбуо, директор, бухгалтер - требует ручного разделения .\n",
    "# TODO: добавить колонку с \"требует ручной работы\" \n",
    "\n",
    "folder = 'data_ids/docx/'\n",
    "\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\"убирает лишние данные\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_unwanted_symbols(df):        \n",
    "        df['name'] = df['name'].apply(lambda x: str(x).replace('\\n', ' '))\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_unwanted_cells(df):\n",
    "        # убирает ячейки с нумерацией\n",
    "\n",
    "        df = df[~df['position'].astype(str).str.isdigit()]\n",
    "        return df\n",
    "\n",
    "    def clean_df(self, df):\n",
    "        df = self.remove_unwanted_symbols(df)\n",
    "        df = self.remove_unwanted_cells(df)\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "class CorrectHeadersParser:\n",
    "\n",
    "    '''класс для парсинга таблиц, у которых на месте колонки, которые нам нужны'''\n",
    "\n",
    "    def table_splitter(self, table: pd.DataFrame, file_name) -> list[pd.DataFrame]:\n",
    "        '''разделяет таблицы, в которых учреждение указано внутри таблицы'''\n",
    "\n",
    "        def check_if_same(my_array: list) -> bool:\n",
    "            '''проверяем одинаковые ли колонки'''\n",
    "\n",
    "            first = my_array[0]\n",
    "            for e in my_array[1:]:\n",
    "                if e != first:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        def get_indexes_to_split(table):\n",
    "            index_to_split = []\n",
    "            for e in range(len(table)):\n",
    "                cols = table.iloc[e,:].values\n",
    "                if check_if_same(cols):\n",
    "                    index_to_split.append(e)\n",
    "            return index_to_split\n",
    "\n",
    "\n",
    "        def split_table(table: pd.DataFrame, index_to_split:Union[int, list[int]], file_name) -> list[pd.DataFrame]:\n",
    "            dfs = np.array_split(table, index_to_split)\n",
    "            dfs = [e for e in dfs if len(e) > 0]\n",
    "\n",
    "            result_dfs = []\n",
    "            for df in dfs:\n",
    "                office = df.iloc[0,:][0]\n",
    "                df = df.iloc[1:,:] \n",
    "                df['office'] = office\n",
    "                result_dfs.append(df)\n",
    "            \n",
    "            result_dfs = [e for e in result_dfs if not e.empty]\n",
    "            try:\n",
    "                result_dfs = pd.concat(result_dfs)\n",
    "                return result_dfs\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print('rogue file---', file_name)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "        index_to_split = get_indexes_to_split(table)\n",
    "\n",
    "        if not index_to_split:\n",
    "            return table\n",
    "\n",
    "        splitted_dfs = split_table(table, index_to_split, file_name)\n",
    "        return splitted_dfs\n",
    "\n",
    "        \n",
    "    def concat_name(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''соединяем колонки ФИО, если они в разных'''\n",
    "        \n",
    "        if 'name' not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        names_df = df['name']\n",
    "        if isinstance(names_df, str) or isinstance(names_df, pd.Series):\n",
    "            return df  \n",
    "        \n",
    "        names = [' '.join(e) for e in names_df.values]     \n",
    "        \n",
    "        df.drop(columns=['name'], inplace=True)\n",
    "        df['name'] = names\n",
    "        return df\n",
    "\n",
    "\n",
    "    def parse(self, table: pd.DataFrame, file_name) -> pd.DataFrame:\n",
    "        table = self.concat_name(table)\n",
    "        table = self.table_splitter(table, file_name)\n",
    "        return table\n",
    "\n",
    "\n",
    "\n",
    "class DocxParser:\n",
    "\n",
    "    def __init__(self):\n",
    "       self.cols_we_need = ['name','salary', 'position', 'department']\n",
    "       self.parse_correct_headers = CorrectHeadersParser()\n",
    "       self.parse_incorrect_headers = ''\n",
    "       self.all_docs: list[dict[str, Document]]\n",
    "       self.data_cleaner = DataCleaner()\n",
    "\n",
    "    # def read_all_docs(self, path: str)->list[dict[str, Document]]:\n",
    "    #     self.path = path\n",
    "    #     all_docs = []\n",
    "    #     i = 0\n",
    "    #     for doc in os.listdir(path)[:50]:\n",
    "    #         if not doc.endswith('docx'):\n",
    "    #             continue\n",
    "\n",
    "    #         try:\n",
    "    #             all_docs.append({'file':doc,'doc':Document(folder + doc)})\n",
    "    #             i +=1\n",
    "    #         except:\n",
    "    #             print('не вышло--', doc)\n",
    "        \n",
    "    #     self.all_docs = all_docs\n",
    "    #     print(f'нашли и загрузили {i} файлов')\n",
    "\n",
    "        \n",
    "    def read_docx_tables(self, filename, tab_id=None, **kwargs):\n",
    "        \"\"\"\n",
    "        parse table(s) fromt.columnsrd Document (.docx) into Pandas DataFrame(s)\n",
    "\n",
    "        Parameters:\n",
    "            filename:   file name of a Word Document\n",
    "\n",
    "            tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                        When [None] - return a list of DataFrames (parse all tables)\n",
    "\n",
    "            kwargs:     arguments to pass to `pd.read_csv()` function\n",
    "\n",
    "        Return: a single DataFrame if tab_id != None or a list of DataFrames otherwise\n",
    "        \"\"\"\n",
    "        def read_docx_tab(tab, **kwargs):\n",
    "            vf = io.StringIO()\n",
    "            writer = csv.writer(vf)\n",
    "            for row in tab.rows:\n",
    "                writer.writerow(cell.text for cell in row.cells)\n",
    "            vf.seek(0)\n",
    "            return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "        doc = Document(filename)\n",
    "        if tab_id is None:\n",
    "            return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "        else:\n",
    "            try:\n",
    "                return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "            except IndexError:\n",
    "                print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "                raise\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def rename_col(col: str) -> str:\n",
    "        col = col.lower()\n",
    "        if re.search(pattern='(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество)', string=col):\n",
    "            return \"name\"\n",
    "\n",
    "        elif re.search(pattern='(cреднемесячная|зарпл.|плат[ы, а]|заработн[ой, ая] плат[а, ы]|cреднемесячн[ая, ой]|зарплат[а, ной, ы])', string=col):\n",
    "            return \"salary\"\n",
    "\n",
    "        elif re.search(pattern='(должност[ь, и, ей])', string=col): \n",
    "\n",
    "            return 'position'\n",
    "\n",
    "        elif re.search(pattern='(предприяти[е,я]|учреждени[е,я]|юридическое лицо)', string=col):\n",
    "            return 'department'\n",
    "\n",
    "        return col\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def check_if_columns_ok(cols: tuple) -> bool:\n",
    "        '''проверяем, есть ли в заголовках таблицы название предприятия и другая инфа'''\n",
    "        \n",
    "        cols = list(map(str, cols))\n",
    "        cols = list(map(str.lower, cols))\n",
    "        print('cols---', cols)\n",
    "        ok_cols = 0\n",
    "        company_found = False\n",
    "        for col in cols:\n",
    "            company_pattern = '(предприяти[е,я]|учреждени[е,я]|юридическ[ое,ие])'\n",
    "            res = re.search(pattern=company_pattern, string=col)\n",
    "            if res:\n",
    "                company_found = True\n",
    "                continue\n",
    "            \n",
    "            name_salary_position_pattern = '(фамилия|имя|фио|ф\\.и\\.о\\.|ф\\.и\\.о|отчество|плат[ы, а]|заработная плата|cреднемесячн[ая, ой]|зарплат[а, ной, ы]|должность|)'\n",
    "            \n",
    "            res = re.search(pattern=name_salary_position_pattern, string=col)\n",
    "            if res:\n",
    "                ok_cols+=1\n",
    "\n",
    "        if company_found and ok_cols > 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def get_all_tables_of_a_doc(self, filename: str) -> list[pd.DataFrame]:\n",
    "\n",
    "        tables = self.read_docx_tables(filename)        \n",
    "        return tables\n",
    "\n",
    "\n",
    "\n",
    "    def parse_doc(self, filename: str) -> pd.DataFrame:\n",
    "        \n",
    "        assert filename.endswith('docx'), 'Формат должен быть .docx!'\n",
    "            \n",
    "        \n",
    "        doc_tables = self.get_all_tables_of_a_doc(filename) \n",
    "        parsed_tables = []\n",
    "        \n",
    "        for table in doc_tables:\n",
    "\n",
    "            # проверяем норм ли заголовки\n",
    "            columns_ok = self.check_if_columns_ok(table)\n",
    "            if not columns_ok:\n",
    "            # если учреждения нет - смотрим параграфы. \n",
    "                # добавить документ в опущенные\n",
    "                pass\n",
    "\n",
    "            else:                \n",
    "                # если заголовки ок, оставляем только нужные\n",
    "\n",
    "                table.columns = [self.rename_col(col) for col in table.columns]\n",
    "                \n",
    "                cols_to_leave = [col for col in table.columns if col in self.cols_we_need]\n",
    "                cols_to_leave = set(cols_to_leave)\n",
    "                \n",
    "                table = table[cols_to_leave]\n",
    "                \n",
    "                # проверяем на наличие вложенных таблиц и фио, разнесенных на несколько стаоблцов\n",
    "                table = self.parse_correct_headers.parse(table, filename)\n",
    "                # убираем лишние ячейки и символы\n",
    "                \n",
    "                \n",
    "                # table = self.data_cleaner.clean_df(table)\n",
    "                # parsed_tables.append(table)\n",
    "                        \n",
    "        parsed_tables = [e for e in parsed_tables if isinstance(e, pd.DataFrame) and not e.empty]\n",
    "        \n",
    "        if isinstance(parsed_tables, list):\n",
    "            if parsed_tables:\n",
    "                concat_tables = pd.concat(parsed_tables)\n",
    "                return concat_tables\n",
    "        \n",
    "        elif isinstance(parsed_tables, pd.DataFrame):\n",
    "            if not parsed_tables.empty:\n",
    "                return concat_tables\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def parse_folder(self, path: str):\n",
    "        all_tables = []\n",
    "        for doc in os.listdir(path):\n",
    "            pass \n",
    "        #for doc in self.all_docs:\n",
    "        #     tables = self.parse_doc(doc)\n",
    "        #     if tables:\n",
    "        #         # return tables\n",
    "        #         #print(tables)\n",
    "        #         # tables = pd.concat(tables)\n",
    "        #         all_tables.append({'file_name':doc, 'df':tables})\n",
    "        \n",
    "        # return all_tables\n",
    "\n",
    "\n",
    "# file = \"186956_2020_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(kul'tura).docx\"\n",
    "# file = \"102907_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(kul'tura).docx\"\n",
    "# file = '101058_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(obrazovanie).docx'\n",
    "# folder = 'data_ids/docx/'\n",
    "\n",
    "parser = DocxParser()\n",
    "# res = parser.parse_doc(folder + file)\n",
    "#res = parser.parse_doc(folder + file)\n",
    "\n",
    "# df = res[0]\n",
    "# df\n",
    "\n",
    "#parser()\n",
    "folder = 'data_ids/pdf/converted/'\n",
    "file = '189828_2020_Rektor,_prorektory,_glavnyi_bukhgalter.docx'\n",
    "file = '186642_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii.docx'\n",
    "file = '179984_2020_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "file = '86680_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "#file = '184284_2019_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(obrazovanie).docx'\n",
    "file = '180480_2020_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(lesnichestva).docx'\n",
    "\n",
    "#doc = Document(folder + file)\n",
    "\n",
    "res = parser.parse_doc(folder + file)\n",
    "res\n",
    "# parser.check_if_columns_ok()\n",
    "\n",
    "# tables = read_docx_tables(folder + file)\n",
    "#len(doc.paragraphs)\n",
    "# dir(doc)\n",
    "# wh = doc.tables[0].table\n",
    "# print(dir(wh))\n",
    "# wh\n",
    "# for e in doc.paragraphs:\n",
    "#     print(e.text)\n",
    "#     print('==')\n",
    "\n",
    "# len(tables)\n",
    "\n",
    "#parser.check_if_columns_ok(df.columns)\n",
    "# for doc in os.listdir(folder):\n",
    "#     if not doc.endswith('docx'):\n",
    "#         continue\n",
    "#     if 'test_rogue' in doc:\n",
    "\n",
    "#         res = parser.parse_doc(folder + doc)\n",
    "#         if isinstance(res, pd.DataFrame):\n",
    "#             print(res)\n",
    "            #res.to_excel(folder + 'cool/' + doc + '.xlsx' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f6270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4ef25252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb02797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "    def read_docx_tables(self, filename, tab_id=None, **kwargs):\n",
    "        \"\"\"\n",
    "        parse table(s) fromt.columnsrd Document (.docx) into Pandas DataFrame(s)\n",
    "\n",
    "        Parameters:\n",
    "            filename:   file name of a Word Document\n",
    "\n",
    "            tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                        When [None] - return a list of DataFrames (parse all tables)\n",
    "\n",
    "            kwargs:     arguments to pass to `pd.read_csv()` function\n",
    "\n",
    "        Return: a single DataFrame if tab_id != None or a list of DataFrames otherwise\n",
    "        \"\"\"\n",
    "        def read_docx_tab(tab, **kwargs):\n",
    "            vf = io.StringIO()\n",
    "            writer = csv.writer(vf)\n",
    "            for row in tab.rows:\n",
    "                writer.writerow(cell.text for cell in row.cells)\n",
    "            vf.seek(0)\n",
    "            return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "        doc = Document(filename)\n",
    "        if tab_id is None:\n",
    "            return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "        else:\n",
    "            try:\n",
    "                return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "            except IndexError:\n",
    "                print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "                raise\n",
    "            \n",
    "# file = '96461_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "# tables = read_docx_tables(folder + file)\n",
    "\n",
    "df = tables[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "58a8af8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'link'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t_df = df.applymap(lambda x: str(x).replace('h','AAAA'))\n",
    "# tdf = t_df[['file', 'extension']] \n",
    "# tdf.rename(columns={'file':'name', 'extension':'name'}, inplace=True)\n",
    "\n",
    "# tdf = tdf[tdf]\n",
    "# tdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''1. Решить че делать с приклеиванием левой колонки к именам (мб по длине отсеить)\n",
    "2. прогнать бывшие пдф\n",
    "3. собрать все вместе\n",
    "\n",
    "'''\n",
    "#df.drop(df.columns[df.apply(lambda col: col.isnull().sum() > 3)], axis=1)\n",
    "#t_df.drop('link', axis=1)\n",
    "\n",
    "# df.apply(lambda x: len())\n",
    "#df.applymap(lambda x: len(str(x)) )\n",
    "# df.iloc[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#eng_df.drop(columns=eng_df.iloc[:,:2].columns.tolist(), inplace=True)\n",
    "\n",
    "# print(df.columns)\n",
    "# to_drop\n",
    "# df.drop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1baf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8801d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22055ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4b5c274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'84706_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii_(ne_ukazany_FIO).docx'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "errors = [\"184385_2020_Rukovoditeli_podvedomstvennykh_uchrezhdenii_(kul'tura).docx\",\n",
    "]\n",
    "errors[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496501f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a84f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_if_columns_ok(cols: tuple) -> bool:\n",
    "    '''проверяем, есть ли в заголовках таблицы название предприятия и другая инфа'''\n",
    "    \n",
    "    cols = list(map(str, cols))\n",
    "    cols = list(map(str.lower, cols))\n",
    "    \n",
    "    ok_cols = 0\n",
    "    company_found = False\n",
    "    for col in cols:\n",
    "        company_pattern = '(предприяти[е,я]|учреждени[е,я]|юридическ[ое,ие])'\n",
    "        res = re.search(pattern=company_pattern, string=col)\n",
    "        if res:\n",
    "            company_found = True\n",
    "            continue\n",
    "        \n",
    "        name_salary_position_pattern = '(фамилия|имя|фио|ф.и.о|отчество|заработная плата|cреднемесячная|зарпл|должность|)'\n",
    "        \n",
    "        res = re.search(pattern=name_salary_position_pattern, string=col)\n",
    "        if res:\n",
    "            ok_cols+=1\n",
    "\n",
    "    if company_found and ok_cols > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "l = ['№ п/п', 'ФИО', 'Должность',\n",
    "       'Среднемесячная заработная плата за 2020 год, руб.']\n",
    "check_if_columns_ok(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556da855",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def read_docx_tables(filename, tab_id=None, **kwargs):\n",
    "    \"\"\"\n",
    "    parse table(s) fromt.columnsrd Document (.docx) into Pandas DataFrame(s)\n",
    "\n",
    "    Parameters:\n",
    "        filename:   file name of a Word Document\n",
    "\n",
    "        tab_id:     parse a single table with the index: [tab_id] (counting from 0).\n",
    "                    When [None] - return a list of DataFrames (parse all tables)\n",
    "\n",
    "        kwargs:     arguments to pass to `pd.read_csv()` function\n",
    "\n",
    "    Return: a single DataFrame if tab_id != None or a list of DataFrames otherwise\n",
    "    \"\"\"\n",
    "    def read_docx_tab(tab, **kwargs):\n",
    "        vf = io.StringIO()\n",
    "        writer = csv.writer(vf)\n",
    "        for row in tab.rows:\n",
    "            writer.writerow(cell.text for cell in row.cells)\n",
    "        vf.seek(0)\n",
    "        return pd.read_csv(vf, **kwargs)\n",
    "\n",
    "    doc = Document(filename)\n",
    "    if tab_id is None:\n",
    "        return [read_docx_tab(tab, **kwargs) for tab in doc.tables]\n",
    "    else:\n",
    "        try:\n",
    "            return read_docx_tab(doc.tables[tab_id], **kwargs)\n",
    "        except IndexError:\n",
    "            print('Error: specified [tab_id]: {}  does not exist.'.format(tab_id))\n",
    "            raise\n",
    "        \n",
    "file = '96461_2019_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.docx'\n",
    "file = folder + file\n",
    "tables = read_docx_tables(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c814969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_folder = 'data_ids/doc/'\n",
    "# file = '83305_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii.doc'\n",
    "\n",
    "# doc = Document(doc_folder+file)\n",
    "# doc\n",
    "\n",
    "import glob\n",
    "\n",
    "# pattern = '*\\*\\*.docx'\n",
    "# pattern2 = '*\\*\\*.doc'\n",
    "# docs = glob.glob(pattern2)\n",
    "# docsX = glob.glob(pattern)\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "import win32com.client as win32\n",
    "from win32com.client import constants\n",
    "\n",
    "# Create list of paths to .doc files\n",
    "paths = glob('D:\\PROGR\\LEARN_PYTHON\\Declarator\\declarations-parser\\data_ids\\doc\\*.doc', recursive=True)\n",
    "\n",
    "def save_as_docx(path):\n",
    "    # Opening MS Word\n",
    "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "    doc = word.Documents.Open(path)\n",
    "    doc.Activate()\n",
    "\n",
    "    # Rename path with .docx\n",
    "    new_file_abs = os.path.abspath(path)\n",
    "    new_file_abs = re.sub(r'\\.\\w+$', '.docx', new_file_abs)\n",
    "    \n",
    "    # Save and Close\n",
    "    word.ActiveDocument.SaveAs(\n",
    "        new_file_abs, FileFormat=constants.wdFormatXMLDocument\n",
    "    )\n",
    "    doc.Close(False)\n",
    "\n",
    "for path in paths:\n",
    "    save_as_docx(path)\n",
    "\n",
    "#set([e[-1] for e in r])\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd5ee944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# TODO: есть еще ситуация - должность и учреждение в одной ячейке. можно решить доп проверкой \n",
    "# - если в должности гбуо, директор, бухгалтер - требует ручного разделения .\n",
    "# TODO: добавить колонку с \"требует ручной работы\" \n",
    "\n",
    "'''1. допарсить, проверить\n",
    "2. сформулировать вопросы\n",
    "3. созвониться\n",
    "4. сделать интерфейс\n",
    "5. рефактор\n",
    "6. пуш'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4dcf55-4e5f-439a-b503-f34ce530325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    " объединяет несколько колонок с именем    \n",
    "'''\n",
    "\n",
    "df = pd.read_excel('data_ids/docx/fio.xlsx', engine='openpyxl')\n",
    "\n",
    "def concat_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    names_df = df['ФИО']\n",
    "    \n",
    "    if isinstance(names_df, str) or isinstance(names_df, pd.Series):\n",
    "        return df  \n",
    "\n",
    "    names_df = names_df.rename(columns={'ФИО':'old_ФИО'})\n",
    "    names_df['ФИО'] = names_df.apply(' '.join, axis=1)\n",
    "\n",
    "    names_df.drop(columns='old_ФИО', inplace=True)    \n",
    "    df.drop(columns='ФИО', inplace=True)\n",
    "    return pd.concat([df, names_df], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # такой парсер, который считывал бы заголовок таблицы\n",
    "# # и надпись перед ним\n",
    "\n",
    "# # если в таблицах нет колонки с учерждением смотрим инфу вокруг\n",
    "# # raw = '83336_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii_(ne_ukazany_FIO).docx'\n",
    "# # raw = folder + raw\n",
    "# # # doc = folder + '83350_2017_Rukovoditeli,_zamestiteli_i_glavnye_bukhgaltery_podvedomstvennykh_uchrezhdenii_(ne_ukazany_FIO).docx'\n",
    "# # docx = Document(raw )\n",
    "# res = []\n",
    "\n",
    "# for doc_dict in all_docs:    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# # dfs = read_docx_tables(doc)\n",
    "# #dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883070f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc343f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fitz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26360/240921394.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fitz'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
